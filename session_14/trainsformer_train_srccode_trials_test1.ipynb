{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"trainsformer_train_srccode_trials_test1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"GVrLZYUTPoev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616349846396,"user_tz":-330,"elapsed":22318,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"26ff3ad2-fc2f-4cd6-d658-a412a8b9a351"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bXUDh9WZTTu_"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"hVev6PWu1uod","executionInfo":{"status":"ok","timestamp":1616349865922,"user_tz":-330,"elapsed":2868,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["# !pip install -U torchtext==0.8.0"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"83TW5iAW45_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616349870230,"user_tz":-330,"elapsed":7154,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"84073043-97be-43dd-c973-d297d2bdef47"},"source":["import torch, torchtext\n","torch.__version__, torchtext.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('1.8.0+cu101', '0.9.0')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Dc5f0B0H5K8e","executionInfo":{"status":"ok","timestamp":1616349873214,"user_tz":-330,"elapsed":10079,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import unicode_literals\n"," \n","import torch\n","from torch.jit import script, trace\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import csv\n","import random\n","import re\n","import os\n","import unicodedata\n","import codecs\n","from io import open\n","import itertools\n","import math\n","import numpy as np\n","import spacy\n","import torchtext\n","from torchtext.legacy import data\n","from torchtext.legacy.data import Field, BucketIterator\n","from tqdm import tqdm as tqdm\n","import random\n","import torchtext.vocab as vocab\n","import time\n","import pickle\n","import tokenize\n","from io import StringIO"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTxKJ9b5ThDB"},"source":["# Global SettingsÂ¶"]},{"cell_type":"code","metadata":{"id":"qZBmTSRETRbx","executionInfo":{"status":"ok","timestamp":1616349873215,"user_tz":-330,"elapsed":8800,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n"," \n","SEED = 1234\n"," \n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n"," \n","# hyperparams\n","BATCH_SIZE = 2\n","learning_rate = 0.0005\n","N_EPOCHS = 15\n","CLIP = 1"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3SnRnW6XTtMs"},"source":["# Dataset Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPWRNuVwrshi","executionInfo":{"status":"ok","timestamp":1616349873216,"user_tz":-330,"elapsed":7411,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"7d93c0a0-3eae-443c-ed10-7dd020ad9088"},"source":["cd drive/MyDrive/personal_projects/END_CAPSTONE/"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1dbJ7ll0kb1GnK_5zt-JldgU9DD-BmZyU/personal_projects/END_CAPSTONE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woFT_reHoMqN","executionInfo":{"status":"ok","timestamp":1616350830846,"user_tz":-330,"elapsed":4517,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"24586438-eade-4f4c-90f0-9969fcbb7a20"},"source":["with open('./dataset/small_dataset/glove_trained_models/embeddings/pygments_glove_embedding.pkl' , 'rb') as f:\n","  embedding_corpus = pickle.load(f)\n","print('shape of the embedding_corpus is ', len(embedding_corpus))\n"," \n","with open('./dataset/small_dataset/transformer_dataset/clean_python_dataset_final.pkl' , 'rb') as f:\n","  python_dataset = pickle.load(f)\n","print('length of the dataset is ', len(python_dataset))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["shape of the embedding_corpus is  667631\n","length of the dataset is  3399\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRUIOaVl9d4Y","executionInfo":{"status":"ok","timestamp":1616350955913,"user_tz":-330,"elapsed":640,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"5d8c40db-a7ec-4a24-bd07-582aa7833acc"},"source":["print('----- testing the format of dataset -----  \\n ')\n","index = random.randint(0,len(python_dataset)-1)\n","print(python_dataset[0])\n","print('\\n')\n","print(python_dataset[index]['code'])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["----- testing the format of dataset -----  \n"," \n","{'obj': 'write a python program to add two numbers', 'code': \"num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\nprint(f'Sum: {sum}')\\n\"}\n","\n","\n","def Celsius_To_Fahrenheit(c):\n","    fahrenheit = (c * 1.8) + 32\n","    return fahrenheit\n","11.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r5NlB3lJB5Fv","executionInfo":{"status":"ok","timestamp":1616351055242,"user_tz":-330,"elapsed":1073,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":[""],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yn5IK00CB-Ov"},"source":["##Tokenizer Demo\n"]},{"cell_type":"code","metadata":{"id":"Ol9UG2qPoPjH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616351155895,"user_tz":-330,"elapsed":598,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"5b24e4f4-9483-45fd-b488-6842b754bd9e"},"source":["######### Code is commented #########\n","# print('python tokenizer demo')\n","# x = python_dataset[0]['code']\n","# tokens = tokenize.generate_tokens(StringIO(x).readline)\n","# for token in tokens:\n","#     print(token)\n","######### Comment ends here #########\n","print(' pygments tokenizer demo')\n","import pygments\n","from pygments.lexers import PythonLexer\n","lexer = PythonLexer()\n","tokens_test = lexer.get_tokens(python_dataset[index]['code'])\n","x = [i for i in tokens_test]\n","print(x[0:5])"],"execution_count":24,"outputs":[{"output_type":"stream","text":[" pygments tokenizer demo\n","[(Token.Keyword, 'def'), (Token.Text, ' '), (Token.Name.Function, 'Celsius_To_Fahrenheit'), (Token.Punctuation, '('), (Token.Name, 'c')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"52OKAsetv09n","executionInfo":{"status":"ok","timestamp":1616351254602,"user_tz":-330,"elapsed":1398,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["spacy_en = spacy.load('en')\n","\n","######### Code is commented #########\n","## python tokenizer is replaced by pygments tokenizer\n","# def tokenize_src_code(text):\n","#     \"\"\"\n","#     Tokenizes src code text from a string into a list of words using python tokenize\n","#     \"\"\"\n","#     return [tok for tok in tokenize.generate_tokens(StringIO(text).readline)]\n","######### Comment ends here #########\n","\n","def tokenize_en(text):\n","    \"\"\"\n","    Tokenizes English text from a string into a list of strings\n","    \"\"\"\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","                                                    \n","lexer = PythonLexer()                                                    \n","def tokenize_src_code_pygments(text):\n","  tokens_org = lexer.get_tokens(text)\n","  tokens_filtered = [i[1] for i in tokens_org if i[0] != pygments.token.Comment.Single]\n","  return tokens_filtered\n","\n","SRC = Field(tokenize = tokenize_en, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True, \n","            batch_first = True)\n","\n","TRG = Field(tokenize = tokenize_src_code_pygments, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = False, \n","            batch_first = True)\n"," \n","fields = [('src', SRC),('trg',TRG)]"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3Lk7Kr37Pmi","executionInfo":{"status":"ok","timestamp":1616351288234,"user_tz":-330,"elapsed":1114,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["######### Code is commented #########\n","# stale_indices = []\n","# new_python_dataset = []\n","# for i in range(len(python_dataset)):\n","#   try:\n","#     test = tokenize_src_code_pygments(python_dataset[i]['code'])\n","#     new_python_dataset.append(python_dataset[i])\n","#   except Exception as e:\n","#     print(e)\n","#     stale_indices.append(i)\n","#     continue\n","######### Comment ends here #########"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEJsNkr8wA3t","executionInfo":{"status":"ok","timestamp":1616351295538,"user_tz":-330,"elapsed":2816,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"e88521e4-98fa-4f20-b4d6-bd224dfd288b"},"source":["# torchtext example\n","example = [data.Example.fromlist([python_dataset[i]['obj'],python_dataset[i]['code']], fields) for i in tqdm(range(len(python_dataset)))]"],"execution_count":28,"outputs":[{"output_type":"stream","text":["100%|ââââââââââ| 3399/3399 [00:02<00:00, 1486.98it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Tp0d_sKpC7wn"},"source":["### removing example with max_len > 512 \n","### this is done to remove cuda error \n","### because token_emb and pos_emb will have shape mismatch in deocder"]},{"cell_type":"code","metadata":{"id":"72CxOp1TVTRF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616351395492,"user_tz":-330,"elapsed":763,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"53d234a1-6072-4fe3-9fb3-439286023316"},"source":["for idx,i in enumerate(example):\n","    if len(i.trg) > 768:\n","        i.trg = i.trg[:767]\n","        \n","max_len = 0\n","avg_len = 0\n","count_len = 0\n","for i in example:\n","    if len(i.trg)>max_len:\n","        max_len = len(i.trg)\n","    if len(i.trg)>512:\n","        count_len+=1\n","    avg_len += len(i.trg)\n","avg_len = avg_len/len(example)\n","print(max_len, avg_len, count_len)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["767 79.83259782288908 31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKvwphLa6NVw","executionInfo":{"status":"ok","timestamp":1615573268359,"user_tz":-330,"elapsed":19966,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"67c263c7-3680-45a0-814d-180db9e4b0b0"},"source":["# testing data\n","index = random.randint(0,1000)\n","example[index].src,example[index].trg"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['73',\n","  'write',\n","  'a',\n","  'python',\n","  'function',\n","  'to',\n","  'print',\n","  'a',\n","  'pattern',\n","  'of',\n","  'stars',\n","  '(',\n","  '*',\n","  ')'],\n"," ['for',\n","  ' ',\n","  'row',\n","  ' ',\n","  'in',\n","  ' ',\n","  'range',\n","  ' ',\n","  '(',\n","  '0',\n","  ',',\n","  '5',\n","  ')',\n","  ':',\n","  '\\n',\n","  '    ',\n","  'for',\n","  ' ',\n","  'column',\n","  ' ',\n","  'in',\n","  ' ',\n","  'range',\n","  ' ',\n","  '(',\n","  '0',\n","  ',',\n","  ' ',\n","  'row',\n","  '+',\n","  '1',\n","  ')',\n","  ':',\n","  '\\n',\n","  '        ',\n","  'print',\n","  ' ',\n","  '(',\n","  '\"',\n","  '*',\n","  '\"',\n","  ',',\n","  ' ',\n","  'end',\n","  '=',\n","  '\"',\n","  '\"',\n","  ')',\n","  '\\n',\n","  '    ',\n","  '\\n',\n","  '    ',\n","  'print',\n","  '(',\n","  \"'\",\n","  '\\\\r',\n","  \"'\",\n","  ')',\n","  '\\n'])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"hIWjItqw6WiZ","executionInfo":{"status":"ok","timestamp":1616351491007,"user_tz":-330,"elapsed":671,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["# creating dataset\n","chatbotDataset = data.Dataset(example, fields)\n","(train_data, valid_data, test_data) = chatbotDataset.split(split_ratio=[0.70, 0.15, 0.15], random_state=random.seed(SEED))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzX_fddNp9vG","executionInfo":{"status":"ok","timestamp":1616351493449,"user_tz":-330,"elapsed":780,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"28284dcb-f5c8-4a8a-9982-f5a849f9402d"},"source":["print('Total training samples --> {}'.format(len(train_data)))\n","print('Total validation samples --> {}'.format(len(valid_data)))\n","print('Total test samples --> {}'.format(len(test_data)))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Total training samples --> 2379\n","Total validation samples --> 510\n","Total test samples --> 510\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feCPBnviqLd6","executionInfo":{"status":"ok","timestamp":1616351496219,"user_tz":-330,"elapsed":725,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"f138675b-2619-426f-db7b-752088f9d2df"},"source":["# testing data\n","index = random.randint(0,500)\n","vars(test_data.examples[index])"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'src': ['write',\n","  'a',\n","  'python',\n","  'program',\n","  'to',\n","  'filter',\n","  'similar',\n","  'case',\n","  'strings',\n","  'and',\n","  'print',\n","  'it'],\n"," 'trg': ['x',\n","  '=',\n","  '[',\n","  ']',\n","  '\\n',\n","  'for',\n","  ' ',\n","  'i',\n","  ' ',\n","  'in',\n","  ' ',\n","  'test_list',\n","  ':',\n","  '\\n',\n","  '    ',\n","  'if',\n","  ' ',\n","  'i',\n","  '.',\n","  'islower',\n","  '(',\n","  ')',\n","  ' ',\n","  'or',\n","  ' ',\n","  'i',\n","  '.',\n","  'isupper',\n","  '(',\n","  ')',\n","  ':',\n","  '\\n',\n","  '        ',\n","  'print',\n","  '(',\n","  'x',\n","  '.',\n","  'append',\n","  '(',\n","  'i',\n","  ')',\n","  ')',\n","  '\\n',\n","  'print',\n","  '(',\n","  'x',\n","  ')',\n","  '\\n']}"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"ZCkHTSzEqSEH","executionInfo":{"status":"ok","timestamp":1616351522511,"user_tz":-330,"elapsed":713,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["# build vocab\n","SRC.build_vocab(train_data, min_freq = 1)\n","TRG.build_vocab(train_data, min_freq = 1)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"oN1-2WtMq1x3","executionInfo":{"status":"ok","timestamp":1616351566659,"user_tz":-330,"elapsed":689,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["######### Code is commented #########\n","# print('loading and processing python corpus tokens')\n","# with open('./dataset/small_dataset/python_corpus_tokens_clean_small.pkl', 'rb') as f:\n","#   python_corpus_tokens_data = pickle.load(f)\n"," \n","# import tokenize\n","# remove_list_temp = ['COMMENT', 'NUMBER' , 'STRING']\n","# token_names = []\n","# python_corpus_tokens = []\n","# for each_token in tqdm(python_corpus_tokens_data):\n","#   token_name = tokenize.tok_name[each_token.type]\n","#   if token_name not in token_names:\n","#     token_names.append(token_name)\n","#   if token_name not in remove_list_temp:\n","#     python_corpus_tokens.append(each_token.string)\n","  \n","# # python_corpus_tokens = [i.string for i in tqdm(python_corpus_tokens_data)]\n","# # # removing duplicates\n","# python_corpus_tokens = list(set(python_corpus_tokens)) \n","# print('total number of python tokens ', len(python_corpus_tokens))\n"," \n","# word2id = {w:i for i,w in enumerate(python_corpus_tokens)}\n","# id2word = {i:w for w, i in word2id.items()}\n","######### Comment ends here #########"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EAd6jFUaEBMa"},"source":["### Loading pre-trained glove embedding into target vocab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5dfQ6Cg8aWF","executionInfo":{"status":"ok","timestamp":1616351635377,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"7af0f297-85be-4a25-8cd8-95134677f912"},"source":["# TODO try a different methos for this\n","# https://discuss.pytorch.org/t/aligning-torchtext-vocab-index-to-loaded-embedding-pre-trained-weights/20878/6\n","sorted_keys = []\n","not_available = []\n","embs = []\n","for each_word in tqdm(TRG.vocab.stoi):\n","  try:\n","    selected_id = word2id[each_word]\n","    sorted_keys.append(selected_id)\n","    temp_emb = embedding_corpus[each_word]\n","    embs.append(temp_emb)\n","  except Exception as e:\n","    not_available.append(each_word)\n","    temp_emb = np.random.uniform(low=-1.0, high=1.0, size=(256,)).astype('float32')\n","    embs.append(temp_emb)\n","pretrained_embs = torch.from_numpy(np.array(embs))\n","TRG.vocab.vectors = pretrained_embs"],"execution_count":35,"outputs":[{"output_type":"stream","text":["100%|ââââââââââ| 4665/4665 [00:00<00:00, 121522.31it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oVd5RTYWHXhZ","executionInfo":{"status":"ok","timestamp":1616351643375,"user_tz":-330,"elapsed":635,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"," \n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.src),\n","    sort_within_batch=True,\n","    device = device)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfx0hx4dLcEe","executionInfo":{"status":"ok","timestamp":1616351655816,"user_tz":-330,"elapsed":11720,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"45b3e6c3-8468-4cb2-fd39-5909b3f1c3cb"},"source":["print('checking out one batch')\n","x = next(iter(train_iterator))\n","print(x.src.shape,x.trg.shape)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["checking out one batch\n","torch.Size([2, 13]) torch.Size([2, 60])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JIu8s10sLgRl","executionInfo":{"status":"ok","timestamp":1616351661998,"user_tz":-330,"elapsed":651,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    Encoder arguments\n","        input_dim --> [src_len,batch_size]\n","        hid_dim --> convert each input word to embedding\n","        n_layers --> number of transformer layers\n","        n_heads --> number of heads for multi head attention\n","        pf_dim --> hidden layer upscaling in pointwise feedforward layer\n","        dropout --> dropout value \n","        device --> gpu or cpu\n","        max_length --> max langth of the sentence, used in positional encoding\n","        \n","    Encoder outputs\n","        src after changing it through the self attention and pointwise feed forward layer\n","        \n","    Encoder description\n","        - combines source and positional embedding\n","        - passes it through self attention layer and calculates attention\n","        - passes attention output to pointwise feed forward layer \n","        - returns the src after passing it to the aforementioned layers\n","'''\n"," \n","class Encoder(nn.Module):\n","    def __init__(self, \n","                 input_dim, \n","                 hid_dim, \n","                 n_layers, \n","                 n_heads, \n","                 pf_dim,\n","                 dropout, \n","                 device,\n","                 max_length = 100):\n","        super().__init__()\n"," \n","        self.device = device\n","        \n","        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n","        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n","        \n","        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n","                                                  n_heads, \n","                                                  pf_dim,\n","                                                  dropout, \n","                                                  device) \n","                                     for _ in range(n_layers)])\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n","        \n","    def forward(self, src, src_mask):\n","        \n","        #src = [batch size, src len]\n","        #src_mask = [batch size, 1, 1, src len]\n","        \n","        batch_size = src.shape[0]\n","        src_len = src.shape[1]\n","        \n","        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        \n","        #pos = [batch size, src len]\n","        \n","        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        for layer in self.layers:\n","            src = layer(src, src_mask)\n","            \n","        #src = [batch size, src len, hid dim]\n","            \n","        return src"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"5abBrHH1Lrmf","executionInfo":{"status":"ok","timestamp":1616351664313,"user_tz":-330,"elapsed":664,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    EncoderLayer arguments\n","    \n","        hid_dim --> convert each input word to embedding\n","        n_heads --> number of heads for multi head attention\n","        pf_dim --> hidden layer upscaling in pointwise feedforward layer\n","        dropout --> dropout value \n","        device --> gpu or cpu\n","        \n","    EncoderLayer outputs\n","        src after changing it through the self attention and pointwise feed forward layer\n","        \n","    EncoderLayer description\n","        -  First It takes the src coming from encoder and passes it through attention mechanism.\n","        -  Then applies the layer norm and feed forward operations on the transformed source\n","'''\n"," \n","class EncoderLayer(nn.Module):\n","    def __init__(self, \n","                 hid_dim, \n","                 n_heads, \n","                 pf_dim,  \n","                 dropout, \n","                 device):\n","        super().__init__()\n","        \n","        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n","        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n","                                                                     pf_dim, \n","                                                                     dropout)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_mask):\n","        \n","        #src = [batch size, src len, hid dim]\n","        #src_mask = [batch size, 1, 1, src len] \n","                \n","        #self attention\n","        _src, _ = self.self_attention(src, src, src, src_mask)\n","        \n","        #dropout, residual connection and layer norm\n","        src = self.self_attn_layer_norm(src + self.dropout(_src))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        #positionwise feedforward\n","        _src = self.positionwise_feedforward(src)\n","        \n","        #dropout, residual and layer norm\n","        src = self.ff_layer_norm(src + self.dropout(_src))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        return src"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZZtg0KgLuqQ","executionInfo":{"status":"ok","timestamp":1616351666482,"user_tz":-330,"elapsed":638,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    MultiHeadAttentionLayer arguments\n","    \n","        hid_dim --> convert each input word to embedding\n","        n_heads --> number of heads for multi head attention\n","        dropout --> dropout value \n","        device --> gpu or cpu\n","        \n","    MultiHeadAttentionLayer outputs\n","        src after changing it through the self attention mechanism and the attention mask\n","        \n","    MultiHeadAttentionLayer description\n","        -  takes the query key and value matrices\n","        -  computes energy by multiplying query and key matrices\n","        -  apply mask on the energy vector\n","        -  while processing the encoder src mask is the mask where the unnecessary pad tokens are removed\n","        -  while processing the decoder trg mask is the mask where future information is masked so that\n","        -  decoder can only see previous and current word while decoding next word\n","        -  the energy matrix is then multiplied by the value matrix to get the final transformed source matrix\n","        -  we also return the attention mask after applying a softmax on the energy vector \n","        -  this could later be used to visually test the attention on words\n","'''\n","class MultiHeadAttentionLayer(nn.Module):\n","    def __init__(self, hid_dim, n_heads, dropout, device):\n","        super().__init__()\n","        \n","        assert hid_dim % n_heads == 0\n","        \n","        self.hid_dim = hid_dim\n","        self.n_heads = n_heads\n","        self.head_dim = hid_dim // n_heads\n","        \n","        self.fc_q = nn.Linear(hid_dim, hid_dim)\n","        self.fc_k = nn.Linear(hid_dim, hid_dim)\n","        self.fc_v = nn.Linear(hid_dim, hid_dim)\n","        \n","        self.fc_o = nn.Linear(hid_dim, hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n","        \n","    def forward(self, query, key, value, mask = None):\n","        \n","        batch_size = query.shape[0]\n","        \n","        #query = [batch size, query len, hid dim]\n","        #key = [batch size, key len, hid dim]\n","        #value = [batch size, value len, hid dim]\n","                \n","        Q = self.fc_q(query)\n","        K = self.fc_k(key)\n","        V = self.fc_v(value)\n","        \n","        #Q = [batch size, query len, hid dim]\n","        #K = [batch size, key len, hid dim]\n","        #V = [batch size, value len, hid dim]\n","                \n","        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        \n","        #Q = [batch size, n heads, query len, head dim]\n","        #K = [batch size, n heads, key len, head dim]\n","        #V = [batch size, n heads, value len, head dim]\n","                \n","        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n","        \n","        #energy = [batch size, n heads, query len, key len]\n","        \n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, -1e10)\n","        \n","        attention = torch.softmax(energy, dim = -1)\n","                \n","        #attention = [batch size, n heads, query len, key len]\n","                \n","        x = torch.matmul(self.dropout(attention), V)\n","        \n","        #x = [batch size, n heads, query len, head dim]\n","        \n","        x = x.permute(0, 2, 1, 3).contiguous()\n","        \n","        #x = [batch size, query len, n heads, head dim]\n","        \n","        x = x.view(batch_size, -1, self.hid_dim)\n","        \n","        #x = [batch size, query len, hid dim]\n","        \n","        x = self.fc_o(x)\n","        \n","        #x = [batch size, query len, hid dim]\n","        \n","        return x, attention"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYcOJjMoLxWV","executionInfo":{"status":"ok","timestamp":1616351669048,"user_tz":-330,"elapsed":661,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    PositionwiseFeedforwardLayer arguments\n","    \n","        hid_dim --> convert each input word to embedding\n","        pf_dim --> hidden layer upscaling in pointwise feedforward layer\n","        dropout --> dropout value \n","        \n","    PositionwiseFeedforwardLayer outputs\n","        src after changing it through couple of linear layers and relu activation\n","        \n","'''\n"," \n","class PositionwiseFeedforwardLayer(nn.Module):\n","    def __init__(self, hid_dim, pf_dim, dropout):\n","        super().__init__()\n","        \n","        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n","        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        #x = [batch size, seq len, hid dim]\n","        \n","        x = self.dropout(torch.relu(self.fc_1(x)))\n","        \n","        #x = [batch size, seq len, pf dim]\n","        \n","        x = self.fc_2(x)\n","        \n","        #x = [batch size, seq len, hid dim]\n","        \n","        return x"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mZ6FMuHLzmG","executionInfo":{"status":"ok","timestamp":1616351677886,"user_tz":-330,"elapsed":685,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    Decoder arguments\n","        output_dim --> [teg_len,batch_size]\n","        hid_dim --> convert each input word to embedding\n","        n_layers --> number of transformer layers\n","        n_heads --> number of heads for multi head attention\n","        pf_dim --> \n","        dropout --> dropout value \n","        device --> gpu or cpu\n","        max_length --> max langth of the sentence, used in positional encoding\n","        \n","    Decoder outputs\n","        trg after changing it through the layers shown in the figure above\n","        \n","    Decoder description\n","        - combines trg and postional embedding\n","        - passes it through the decoder layers as shown in the figure \n","        - the final output is passed through linear layer to match output vocab dimension\n","        - we would later do softmax on this output to find the best word prediction\n"," \n","'''\n"," \n","class Decoder(nn.Module):\n","    def __init__(self, \n","                 output_dim, \n","                 hid_dim, \n","                 n_layers, \n","                 n_heads, \n","                 pf_dim, \n","                 dropout, \n","                 device,\n","                 max_length = 1024):\n","        super().__init__()\n","        \n","        self.device = device\n","        \n","        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n","        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n"," \n","        weight_matrix = TRG.vocab.vectors\n","        self.tok_embedding.weight.data.copy_(weight_matrix )\n"," \n","        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n","                                                  n_heads, \n","                                                  pf_dim, \n","                                                  dropout, \n","                                                  device)\n","                                     for _ in range(n_layers)])\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n","        \n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        \n","        #trg = [batch size, trg len]\n","        #enc_src = [batch size, src len, hid dim]\n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        #src_mask = [batch size, 1, 1, src len]\n","                \n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","        \n","        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","                            \n","        #pos = [batch size, trg len]\n","            \n","        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n","                \n","        #trg = [batch size, trg len, hid dim]\n","        \n","        for layer in self.layers:\n","            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        output = self.fc_out(trg)\n","        \n","        #output = [batch size, trg len, output dim]\n","            \n","        return output, attention"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDVTLmLCL2ir","executionInfo":{"status":"ok","timestamp":1616351680019,"user_tz":-330,"elapsed":664,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["'''\n","    DecoderLayer arguments\n","    \n","        hid_dim --> convert each input word to embedding\n","        n_heads --> number of heads for multi head attention\n","        pf_dim --> hidden layer upscaling in pointwise feedforward layer\n","        dropout --> dropout value \n","        device --> gpu or cpu\n","        \n","    DecoderLayer outputs\n","        trg after changing it through the self attention and pointwise feed forward layers\n","        \n","    DecoderLayer description\n","        - The decoder layer is almost as same as encoder layer with thr following changes\n","        - decoder layer uses 2 attention layers\n","        - first trg goes through self attention layer and attention is calculated, here trg is masked using trg_mask\n","        - attention output is then passed through add and layernorm block\n","        - again we calculate attention using encoder key value and decoder query\n","        - this 2nd attention output is then passed through add and layernorm block\n","'''\n"," \n","class DecoderLayer(nn.Module):\n","    def __init__(self, \n","                 hid_dim, \n","                 n_heads, \n","                 pf_dim, \n","                 dropout, \n","                 device):\n","        super().__init__()\n","        \n","        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n","        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n","        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n","                                                                     pf_dim, \n","                                                                     dropout)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #enc_src = [batch size, src len, hid dim]\n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        #src_mask = [batch size, 1, 1, src len]\n","        \n","        #self attention\n","        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n","        \n","        #dropout, residual connection and layer norm\n","        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n","            \n","        #trg = [batch size, trg len, hid dim]\n","            \n","        #encoder attention\n","        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n","        # query, key, value\n","        \n","        #dropout, residual connection and layer norm\n","        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n","                    \n","        #trg = [batch size, trg len, hid dim]\n","        \n","        #positionwise feedforward\n","        _trg = self.positionwise_feedforward(trg)\n","        \n","        #dropout, residual and layer norm\n","        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        return trg, attention"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQGPOOJwL45p","executionInfo":{"status":"ok","timestamp":1616351682207,"user_tz":-330,"elapsed":819,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, \n","                 encoder, \n","                 decoder, \n","                 src_pad_idx, \n","                 trg_pad_idx, \n","                 device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.device = device\n","        \n","    def make_src_mask(self, src):\n","        \n","        #src = [batch size, src len]\n","        \n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n"," \n","        #src_mask = [batch size, 1, 1, src len]\n"," \n","        return src_mask\n","    \n","    def make_trg_mask(self, trg):\n","        \n","        #trg = [batch size, trg len]\n","        \n","        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n","        \n","        #trg_pad_mask = [batch size, 1, 1, trg len]\n","        \n","        trg_len = trg.shape[1]\n","        \n","        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n","        \n","        #trg_sub_mask = [trg len, trg len]\n","            \n","        trg_mask = trg_pad_mask & trg_sub_mask\n","        \n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        \n","        return trg_mask\n"," \n","    def forward(self, src, trg):\n","        \n","        #src = [batch size, src len]\n","        #trg = [batch size, trg len]\n","                \n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","        \n","        #src_mask = [batch size, 1, 1, src len]\n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        \n","        enc_src = self.encoder(src, src_mask)\n","        \n","        #enc_src = [batch size, src len, hid dim]\n","                \n","        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n","        \n","        #output = [batch size, trg len, output dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        return output, attention"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"17X9l7eHL8VP","executionInfo":{"status":"ok","timestamp":1616351688582,"user_tz":-330,"elapsed":653,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","HID_DIM = 256\n","ENC_LAYERS = 3\n","DEC_LAYERS = 3\n","ENC_HEADS = 8\n","DEC_HEADS = 8\n","ENC_PF_DIM = 512\n","DEC_PF_DIM = 512\n","ENC_DROPOUT = 0.1\n","DEC_DROPOUT = 0.1\n"," \n","enc = Encoder(INPUT_DIM, \n","              HID_DIM, \n","              ENC_LAYERS, \n","              ENC_HEADS, \n","              ENC_PF_DIM, \n","              ENC_DROPOUT, \n","              device)\n"," \n","dec = Decoder(OUTPUT_DIM, \n","              HID_DIM, \n","              DEC_LAYERS, \n","              DEC_HEADS, \n","              DEC_PF_DIM, \n","              DEC_DROPOUT, \n","              device)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMzujPJHMAax","executionInfo":{"status":"ok","timestamp":1616351692227,"user_tz":-330,"elapsed":1279,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n"," \n","model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UP3HgNZEMGpg","executionInfo":{"status":"ok","timestamp":1616351693432,"user_tz":-330,"elapsed":612,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"df1b8484-c976-4c93-8114-9c7e427d6dc3"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"," \n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":47,"outputs":[{"output_type":"stream","text":["The model has 7,067,449 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NmZv_8qhMJy0","executionInfo":{"status":"ok","timestamp":1616351695666,"user_tz":-330,"elapsed":662,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.xavier_uniform_(m.weight.data)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"32b1-vMoMRMu","executionInfo":{"status":"ok","timestamp":1616351697467,"user_tz":-330,"elapsed":723,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["model.apply(initialize_weights);"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Hexw4lMTJt","executionInfo":{"status":"ok","timestamp":1616351697799,"user_tz":-330,"elapsed":719,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["LEARNING_RATE = 0.0005\n"," \n","optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AfbHXTFMWMX","executionInfo":{"status":"ok","timestamp":1616351699349,"user_tz":-330,"elapsed":614,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"szXrhFN-MZMJ","executionInfo":{"status":"ok","timestamp":1616351702445,"user_tz":-330,"elapsed":804,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output, _ = model(src, trg[:,:-1])\n","                \n","        #output = [batch size, trg len - 1, output dim]\n","        #trg = [batch size, trg len]\n","            \n","        output_dim = output.shape[-1]\n","            \n","        output = output.contiguous().view(-1, output_dim)\n","        trg = trg[:,1:].contiguous().view(-1)\n","                \n","        #output = [batch size * trg len - 1, output dim]\n","        #trg = [batch size * trg len - 1]\n","            \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgwPpk65McxI","executionInfo":{"status":"ok","timestamp":1616351702961,"user_tz":-330,"elapsed":567,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n"," \n","            src = batch.src\n","            trg = batch.trg\n"," \n","            output, _ = model(src, trg[:,:-1])\n","            \n","            #output = [batch size, trg len - 1, output dim]\n","            #trg = [batch size, trg len]\n","            \n","            output_dim = output.shape[-1]\n","            \n","            output = output.contiguous().view(-1, output_dim)\n","            trg = trg[:,1:].contiguous().view(-1)\n","            \n","            #output = [batch size * trg len - 1, output dim]\n","            #trg = [batch size * trg len - 1]\n","            \n","            loss = criterion(output, trg)\n"," \n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmLVu-6xMe1-","executionInfo":{"status":"ok","timestamp":1616351705123,"user_tz":-330,"elapsed":1123,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"-emruPQxMg_Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616352274970,"user_tz":-330,"elapsed":550064,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"bddaf6a5-30a0-45d1-a05b-886f1721709b"},"source":["best_valid_loss = float('inf')\n","N_EPOCHS = 15\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        # torch.save(model.state_dict(), './dataset/small_dataset/trained_srcgen_model/srcgen_chatbot.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 37s\n","\tTrain Loss: 3.098 | Train PPL:  22.156\n","\t Val. Loss: 2.565 |  Val. PPL:  12.995\n","Epoch: 02 | Time: 0m 36s\n","\tTrain Loss: 2.366 | Train PPL:  10.657\n","\t Val. Loss: 2.281 |  Val. PPL:   9.784\n","Epoch: 03 | Time: 0m 36s\n","\tTrain Loss: 2.071 | Train PPL:   7.937\n","\t Val. Loss: 2.134 |  Val. PPL:   8.447\n","Epoch: 04 | Time: 0m 36s\n","\tTrain Loss: 1.851 | Train PPL:   6.364\n","\t Val. Loss: 1.980 |  Val. PPL:   7.243\n","Epoch: 05 | Time: 0m 36s\n","\tTrain Loss: 1.663 | Train PPL:   5.274\n","\t Val. Loss: 1.876 |  Val. PPL:   6.530\n","Epoch: 06 | Time: 0m 36s\n","\tTrain Loss: 1.500 | Train PPL:   4.483\n","\t Val. Loss: 1.827 |  Val. PPL:   6.218\n","Epoch: 07 | Time: 0m 36s\n","\tTrain Loss: 1.366 | Train PPL:   3.919\n","\t Val. Loss: 1.774 |  Val. PPL:   5.897\n","Epoch: 08 | Time: 0m 36s\n","\tTrain Loss: 1.257 | Train PPL:   3.516\n","\t Val. Loss: 1.746 |  Val. PPL:   5.733\n","Epoch: 09 | Time: 0m 36s\n","\tTrain Loss: 1.160 | Train PPL:   3.189\n","\t Val. Loss: 1.710 |  Val. PPL:   5.529\n","Epoch: 10 | Time: 0m 36s\n","\tTrain Loss: 1.083 | Train PPL:   2.953\n","\t Val. Loss: 1.711 |  Val. PPL:   5.536\n","Epoch: 11 | Time: 0m 36s\n","\tTrain Loss: 1.015 | Train PPL:   2.759\n","\t Val. Loss: 1.686 |  Val. PPL:   5.397\n","Epoch: 12 | Time: 0m 36s\n","\tTrain Loss: 0.956 | Train PPL:   2.602\n","\t Val. Loss: 1.679 |  Val. PPL:   5.362\n","Epoch: 13 | Time: 0m 36s\n","\tTrain Loss: 0.910 | Train PPL:   2.484\n","\t Val. Loss: 1.658 |  Val. PPL:   5.250\n","Epoch: 14 | Time: 0m 36s\n","\tTrain Loss: 0.868 | Train PPL:   2.381\n","\t Val. Loss: 1.685 |  Val. PPL:   5.393\n","Epoch: 15 | Time: 0m 36s\n","\tTrain Loss: 0.836 | Train PPL:   2.307\n","\t Val. Loss: 1.695 |  Val. PPL:   5.449\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ERkE--cQwdW","executionInfo":{"status":"ok","timestamp":1616352311013,"user_tz":-330,"elapsed":654,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","    \n","    model.eval()\n","        \n","    tokens = [token.lower() for token in sentence]\n","\n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","        \n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n","    \n","    src_mask = model.make_src_mask(src_tensor)\n","    \n","    with torch.no_grad():\n","        enc_src = model.encoder(src_tensor, src_mask)\n","\n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","    for i in range(max_len):\n","\n","        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","\n","        trg_mask = model.make_trg_mask(trg_tensor)\n","        \n","        with torch.no_grad():\n","            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n","        \n","        pred_token = output.argmax(2)[:,-1].item()\n","        \n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","    \n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","    \n","    return trg_tokens[1:], attention"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPwiL6qDGy0z","executionInfo":{"status":"ok","timestamp":1616352312713,"user_tz":-330,"elapsed":658,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}}},"source":["# test on one exmaple\n","def chatting(example_idx):\n","    src = vars(test_data.examples[example_idx])['src']\n","    trg = vars(test_data.examples[example_idx])['trg']\n","\n","    src_sen = ' '.join(src)\n","    trg_sen = ' '.join(trg)\n","    print('---------------------------------------')\n","    print(f'Actual src is ==> \\n {src_sen}')\n","    print(f'Actual trg is ==> \\n {trg_sen}')\n","\n","    translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","    translation_sen = translation[:-1]\n","    translation_sen = ' '.join(translation_sen)\n","    print(f'Predicted trg is ==>\\n {translation_sen}')\n","    print('---------------------------------------')\n","    return src_sen,trg_sen,translation[:-1]"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRMGYpO5G6lu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616352316207,"user_tz":-330,"elapsed":713,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"95568726-8085-4aae-db20-bd080e18579d"},"source":["example_idx = random.randint(0,len(test_data))\n","src,trg,translation = chatting(example_idx)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["---------------------------------------\n","Actual src is ==> \n"," write a function to return the speed of moving object based of distance travelled in given time\n","Actual trg is ==> \n"," def   cal_speed ( distance : float , time : float ) - > float : \n","      return   distance / time \n","\n","Predicted trg is ==>\n"," def   cal_density ( mass / volume ) : \n","      return   ( mass / volume ) \n","\n","---------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qEcTWgNGzvn","executionInfo":{"status":"ok","timestamp":1616352331378,"user_tz":-330,"elapsed":592,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"0dbf8162-a020-4261-edd9-b0bf9b1bc6fd"},"source":["example_idx = random.randint(0,len(test_data))\n","src,trg,translation = chatting(example_idx)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["---------------------------------------\n","Actual src is ==> \n"," write a python program to print the even numbers from a given list\n","Actual trg is ==> \n"," def   is_even_num ( l ) : \n"," enum   =   [ ] \n"," for   n   in   l : \n"," if   n   %   2   ==   0 : \n"," enum . append ( n ) \n"," return   enum \n"," print ( is_even_num ( [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ,   7 ,   8 ,   9 ] ) ) \n","\n","Predicted trg is ==>\n"," list1   =   [ 11 ,   - 21 ,   0 ,   0 ,   0 ,   - 45 ,   66 ,   - 93 ] \n"," for   num   in   list1 : \n","      if   num   <   0\n","---------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MgKBaJdG2uv","executionInfo":{"status":"ok","timestamp":1616352357599,"user_tz":-330,"elapsed":887,"user":{"displayName":"Trinanjan Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipfCBKWKbXo-US0MVpIYaUnF-NJhwFIMMRY99znQ=s64","userId":"04053274871203917390"}},"outputId":"61dc23e5-fad0-4f45-9876-a0799b3ec0b9"},"source":["example_idx = random.randint(0,len(test_data))\n","src,trg,translation = chatting(example_idx)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["---------------------------------------\n","Actual src is ==> \n"," write a python function to multiply all values in a list\n","Actual trg is ==> \n"," def   multiplyList ( myList )   : \n","      result   =   1 \n","      for   x   in   myList : \n","          result   =   result   *   x \n","      return   result \n","\n","Predicted trg is ==>\n"," def   reverse_string ( str_to_be_reversed ) : \n","      return   str_to_be_reversed [ : : : - 1 ] \n","\n","---------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R9W6lI9HG7Se"},"source":["# def tokenize_src_code_test(text):\n","#     \"\"\"\n","#     Tokenizes src code text from a string into a list of words using python tokenize\n","#     \"\"\"\n","#     return [tok for tok in tokenize.generate_tokens(StringIO(text).readline)]\n","\n","# tokenize.untokenize(tokenize_src_code_test(trg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hGifcvTHkvP"},"source":["#todo\n","# 1. check the embedding weight copy part\n","# 2. check the max_len part that was showing cuda error\n","# 3. save pretrained embedding in vector format\n","# 4. save output to text file\n","# 5. https://github.com/bentrevett/pytorch-sentiment-analysis/blob/69fc4b0c6952247c33dc9fc7f09123dbd1ef023b/C%20-%20Loading%2C%20Saving%20and%20Freezing%20Embeddings.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVMfCb87Sp4X"},"source":[""],"execution_count":null,"outputs":[]}]}