{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation by Jointly Learning to Align and Translate\n",
    "\n",
    "In this third notebook on sequence-to-sequence models using PyTorch and TorchText, we'll be implementing the model from [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473). This model achives our best perplexity yet, ~27 compared to ~34 for the previous model.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Here is the general encoder-decoder model:\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\n",
    "\n",
    "In the previous model, our architecture was set-up in a way to reduce \"information compression\" by explicitly passing the context vector, $z$, to the decoder at every time-step and by passing both the context vector and embedded input word, $d(y_t)$, along with the hidden state, $s_t$, to the linear layer, $f$, to make a prediction.\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq7.png?raw=1)\n",
    "\n",
    "Even though we have reduced some of this compression, our context vector still needs to contain all of the information about the source sentence. The model implemented in this notebook avoids this compression by allowing the decoder to look at the entire source sentence (via its hidden states) at each decoding step! How does it do this? It uses *attention*. \n",
    "\n",
    "Attention works by first, calculating an attention vector, $a$, that is the length of the source sentence. The attention vector has the property that each element is between 0 and 1, and the entire vector sums to 1. We then calculate a weighted sum of our source sentence hidden states, $H$, to get a weighted source vector, $w$. \n",
    "\n",
    "$$w = \\sum_{i}a_ih_i$$\n",
    "\n",
    "We calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction. We'll explain how to do all of this during the session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:19.641249Z",
     "start_time": "2021-01-26T16:24:19.267576Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext import data\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:20.538203Z",
     "start_time": "2021-01-26T16:24:20.535428Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:20.883367Z",
     "start_time": "2021-01-26T16:24:20.880370Z"
    }
   },
   "outputs": [],
   "source": [
    "# downloading spacy english\n",
    "# %%bash\n",
    "# python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing the Dataset\n",
    "\n",
    "Link to the dataset https://rajpurkar.github.io/SQuAD-explorer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:22.245535Z",
     "start_time": "2021-01-26T16:24:21.538164Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../datasets/Question-Answer Datasets for Chatbot Training/train-v2.0.json\") as f:\n",
    "    squad_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:23.453455Z",
     "start_time": "2021-01-26T16:24:23.446320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When did Beyonce start becoming popular?',\n",
       "  'id': '56be85543aeaaa14008c9063',\n",
       "  'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "  'id': '56be85543aeaaa14008c9065',\n",
       "  'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
       "  'is_impossible': False},\n",
       " {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       "  'id': '56be85543aeaaa14008c9066',\n",
       "  'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'In what city and state did Beyonce  grow up? ',\n",
       "  'id': '56bf6b0f3aeaaa14008c9601',\n",
       "  'answers': [{'text': 'Houston, Texas', 'answer_start': 166}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'In which decade did Beyonce become famous?',\n",
       "  'id': '56bf6b0f3aeaaa14008c9602',\n",
       "  'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'In what R&B group was she the lead singer?',\n",
       "  'id': '56bf6b0f3aeaaa14008c9603',\n",
       "  'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'What album made her a worldwide known artist?',\n",
       "  'id': '56bf6b0f3aeaaa14008c9604',\n",
       "  'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "  'is_impossible': False},\n",
       " {'question': \"Who managed the Destiny's Child group?\",\n",
       "  'id': '56bf6b0f3aeaaa14008c9605',\n",
       "  'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'When did Beyoncé rise to fame?',\n",
       "  'id': '56d43c5f2ccc5a1400d830a9',\n",
       "  'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "  'is_impossible': False},\n",
       " {'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
       "  'id': '56d43c5f2ccc5a1400d830aa',\n",
       "  'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'What was the first album Beyoncé released as a solo artist?',\n",
       "  'id': '56d43c5f2ccc5a1400d830ab',\n",
       "  'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'When did Beyoncé release Dangerously in Love?',\n",
       "  'id': '56d43c5f2ccc5a1400d830ac',\n",
       "  'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'How many Grammy awards did Beyoncé win for her first solo album?',\n",
       "  'id': '56d43c5f2ccc5a1400d830ad',\n",
       "  'answers': [{'text': 'five', 'answer_start': 590}],\n",
       "  'is_impossible': False},\n",
       " {'question': \"What was Beyoncé's role in Destiny's Child?\",\n",
       "  'id': '56d43ce42ccc5a1400d830b4',\n",
       "  'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "  'is_impossible': False},\n",
       " {'question': \"What was the name of Beyoncé's first solo album?\",\n",
       "  'id': '56d43ce42ccc5a1400d830b5',\n",
       "  'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "  'is_impossible': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_data[\"data\"][0][\"paragraphs\"][0][\"qas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:24.673301Z",
     "start_time": "2021-01-26T16:24:24.670392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_data[\"data\"][0][\"paragraphs\"][0][\"context\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "### So converting the data above in a format having (context+question, answer) to be fed for training.\n",
    "While combining context and question we will add one string \"<mos>\" to distinguish between context(paragraph) and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:26.100191Z",
     "start_time": "2021-01-26T16:24:25.876196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:00<00:00, 2035.23it/s]\n"
     ]
    }
   ],
   "source": [
    "quescontext_ans_pairs = []\n",
    "\n",
    "for article in (tqdm(squad_data[\"data\"])):\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            quescontext = context + \"<mos> \" + qa[\"question\"]\n",
    "            if not qa[\"is_impossible\"]:\n",
    "                answer = qa[\"answers\"][0][\"text\"]\n",
    "            else:\n",
    "                answer = \"is impossilbe\"\n",
    "            quescontext_ans_pairs.append([quescontext, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:29.147387Z",
     "start_time": "2021-01-26T16:24:29.145214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quescontext_ans_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:32.214650Z",
     "start_time": "2021-01-26T16:24:32.211975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".<mos> When did Beyonce start becoming popular?',\n",
       " 'in the late 1990s']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quescontext_ans_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question and Answer are standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:36.146322Z",
     "start_time": "2021-01-26T16:24:35.248123Z"
    }
   },
   "outputs": [],
   "source": [
    "Question = Field(sequential = True,\n",
    "                      tokenize = 'spacy',\n",
    "#                       batch_first =True,\n",
    "                      include_lengths=True,\n",
    "                      init_token = '<sos>',\n",
    "                      eos_token = '<eos>',\n",
    "                      lower = True)\n",
    "\n",
    "Answer = Field(sequential = True,\n",
    "                    tokenize ='spacy',\n",
    "#                     batch_first =True,\n",
    "                    include_lengths=True,\n",
    "                    init_token = '<sos>',\n",
    "                    eos_token = '<eos>',\n",
    "                    lower = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the list quescontext_ans_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:24:39.193492Z",
     "start_time": "2021-01-26T16:24:39.191520Z"
    }
   },
   "outputs": [],
   "source": [
    "# fields = [('questions', Question),('answers',Answer)]\n",
    "fields = [('questions', Question),('answers',Question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:26:43.113773Z",
     "start_time": "2021-01-26T16:24:42.235651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130319/130319 [02:00<00:00, 1078.14it/s]\n"
     ]
    }
   ],
   "source": [
    "example = [data.Example.fromlist([quescontext_ans_pairs[i][0],quescontext_ans_pairs[i][1]], fields) for i in tqdm(range(len(quescontext_ans_pairs)))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:26:47.566100Z",
     "start_time": "2021-01-26T16:26:46.342002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwods: Package 'stopwods' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwods')\n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(word_list):\n",
    "    return [word for word in word_list if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:26:50.833472Z",
     "start_time": "2021-01-26T16:26:50.830181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:26:54.115862Z",
     "start_time": "2021-01-26T16:26:54.113433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:18.230696Z",
     "start_time": "2021-01-26T16:26:57.338023Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, i in tqdm(enumerate(example)):\n",
    "    example[idx].questions = remove_stopwords(i.questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:21.475876Z",
     "start_time": "2021-01-26T16:27:21.470607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:24.748919Z",
     "start_time": "2021-01-26T16:27:24.747391Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating dataset\n",
    "squadDataset = data.Dataset(example, fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can split into training, testing, and validation sets by using the split() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:28.132975Z",
     "start_time": "2021-01-26T16:27:28.060866Z"
    }
   },
   "outputs": [],
   "source": [
    "(train, valid, test) = squadDataset.split(split_ratio=[0.70, 0.15, 0.15], random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:31.511840Z",
     "start_time": "2021-01-26T16:27:31.509216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91223, 19548, 19548)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:34.700515Z",
     "start_time": "2021-01-26T16:27:34.697314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['another',\n",
       "  'issue',\n",
       "  'use',\n",
       "  'hypopodium',\n",
       "  'standing',\n",
       "  'platform',\n",
       "  'support',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'given',\n",
       "  'hands',\n",
       "  'may',\n",
       "  'able',\n",
       "  'support',\n",
       "  'weight',\n",
       "  '.',\n",
       "  '17th',\n",
       "  'century',\n",
       "  'rasmus',\n",
       "  'bartholin',\n",
       "  'considered',\n",
       "  'number',\n",
       "  'analytical',\n",
       "  'scenarios',\n",
       "  'topic',\n",
       "  '.',\n",
       "  '20th',\n",
       "  'century',\n",
       "  ',',\n",
       "  'forensic',\n",
       "  'pathologist',\n",
       "  'frederick',\n",
       "  'zugibe',\n",
       "  'performed',\n",
       "  'number',\n",
       "  'crucifixion',\n",
       "  'experiments',\n",
       "  'using',\n",
       "  'ropes',\n",
       "  'hang',\n",
       "  'human',\n",
       "  'subjects',\n",
       "  'various',\n",
       "  'angles',\n",
       "  'hand',\n",
       "  'positions',\n",
       "  '.',\n",
       "  'experiments',\n",
       "  'support',\n",
       "  'angled',\n",
       "  'suspension',\n",
       "  ',',\n",
       "  'two',\n",
       "  '-',\n",
       "  'beamed',\n",
       "  'cross',\n",
       "  ',',\n",
       "  'perhaps',\n",
       "  'form',\n",
       "  'foot',\n",
       "  'support',\n",
       "  ',',\n",
       "  'given',\n",
       "  'aufbinden',\n",
       "  'form',\n",
       "  'suspension',\n",
       "  'straight',\n",
       "  'stake',\n",
       "  '(',\n",
       "  'used',\n",
       "  'nazis',\n",
       "  'dachau',\n",
       "  'concentration',\n",
       "  'camp',\n",
       "  'world',\n",
       "  'war',\n",
       "  'ii',\n",
       "  ')',\n",
       "  ',',\n",
       "  'death',\n",
       "  'comes',\n",
       "  'rather',\n",
       "  'quickly.<mos',\n",
       "  '>',\n",
       "  'said',\n",
       "  'used',\n",
       "  'platform',\n",
       "  'crucifixion',\n",
       "  '?'],\n",
       " 'answers': ['a', 'hypopodium']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train.examples[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "copied from the repository of Woncoh1 https://github.com/woncoh1/END/blob/main/Assignment_Session_7_Sentiment_Analysis_using_LSTM_RNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:37.993524Z",
     "start_time": "2021-01-26T16:27:37.957423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/deep/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries and prepare sentence text\n",
    "\n",
    "import random\n",
    "# for back translation\n",
    "import google_trans_new\n",
    "from google_trans_new import google_translator\n",
    "# for word tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:41.620904Z",
     "start_time": "2021-01-26T16:27:41.171843Z"
    }
   },
   "outputs": [],
   "source": [
    "# translate a sentence to a random language,\n",
    "# and translate back to original language\n",
    "\n",
    "def back_translate(sentence, p=0.1):\n",
    "    # do nothing with probability of 1-p\n",
    "    if random.uniform(0,1) > p:\n",
    "        return sentence\n",
    "    \n",
    "    # combine tokenized sentence into one string\n",
    "    sentence = \" \".join(sentence)\n",
    "    \n",
    "    # instantiate translator\n",
    "    translator = google_translator()\n",
    "    \n",
    "    # choose a target language\n",
    "    available_langs = list(google_trans_new.LANGUAGES.keys())\n",
    "    trans_lang = random.choice(available_langs)\n",
    "    \n",
    "    # translate to the target language\n",
    "    translations = translator.translate(sentence, lang_tgt=trans_lang)\n",
    "    \n",
    "    # translate back to original language\n",
    "    translations_en_random = translator.translate(translations, lang_src=trans_lang, lang_tgt=\"en\")\n",
    "    \n",
    "    # select only one translation\n",
    "    if len(translations_en_random) > 1:\n",
    "        translations_en_random = translations_en_random[0]\n",
    "        \n",
    "    return word_tokenize(translations_en_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:44.932433Z",
     "start_time": "2021-01-26T16:27:44.929375Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly delete words from a sentence with a given probability\n",
    "\n",
    "def random_deletion(sentence, p=0.5): \n",
    "    # return if single word\n",
    "    if len(sentence) == 1: \n",
    "        return sentence\n",
    "    # delete words\n",
    "    remaining = list(filter(lambda x: random.uniform(0,1) > p, sentence)) \n",
    "    # if nothing left, sample a random word\n",
    "    if len(remaining) == 0: \n",
    "        return [random.choice(sentence)] \n",
    "    else:\n",
    "        return remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:27:48.349504Z",
     "start_time": "2021-01-26T16:27:48.347098Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly swap a pair of words in a sentence for a given # of times\n",
    "\n",
    "def random_swap(sentence, n=5): \n",
    "    if len(sentence) < 2:\n",
    "        return sentence\n",
    "    length = range(len(sentence)) \n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(length, 2)\n",
    "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carry Out Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:37:24.183327Z",
     "start_time": "2021-01-26T16:27:51.561619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91223/91223 [09:32<00:00, 159.31it/s] \n"
     ]
    }
   ],
   "source": [
    "for example in tqdm(train.examples): \n",
    "    example.questions = back_translate(example.questions, p=0.01)\n",
    "    example.questions = random_deletion(example.questions, p=0.1)\n",
    "    example.questions = random_swap(example.questions, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:46:45.650153Z",
     "start_time": "2021-01-26T16:46:44.224989Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "''' Use max of 25000 frequently occuring words to create vocabulary. Use pretrained fasttext embedding. Embedding of words that exist in the data but not in the\n",
    "dictionary are set using normal distribution.\n",
    "'''\n",
    "Question.build_vocab(train,\n",
    "                     max_size = MAX_VOCAB_SIZE,\n",
    "                     vectors='fasttext.simple.300d',\n",
    "                     unk_init = torch.Tensor.normal_,\n",
    "                     min_freq = 2)\n",
    "Answer.build_vocab(train,\n",
    "                   vectors='fasttext.simple.300d',\n",
    "                   min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:46:48.843461Z",
     "start_time": "2021-01-26T16:46:48.841821Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the vocab instance\n",
    "vocab = Question.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:46:52.049424Z",
     "start_time": "2021-01-26T16:46:52.046633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25004, 300])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector = Question.vocab.vectors\n",
    "embedding_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:46:55.301436Z",
     "start_time": "2021-01-26T16:46:55.284954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of context+question vocab :  25004\n",
      "Size of answer vocab :  4\n",
      "Top 10 words appeared in contex+question: [(',', 624240), ('.', 325459), ('\"', 104398), ('-', 102183), ('(', 89076), (')', 85255), ('>', 81566), ('?', 81362), (\"'s\", 67096), ('is', 31131)]\n",
      "Top 10 words appeared in answer: []\n"
     ]
    }
   ],
   "source": [
    "print('Size of context+question vocab : ', len(Question.vocab))\n",
    "print('Size of answer vocab : ', len(Answer.vocab))\n",
    "print('Top 10 words appeared in contex+question:', list(Question.vocab.freqs.most_common(10)))\n",
    "print(\"Top 10 words appeared in answer:\", list(Answer.vocab.freqs.most_common(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:38.630609Z",
     "start_time": "2021-01-26T16:45:38.571074Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:41.920516Z",
     "start_time": "2021-01-26T16:45:41.918537Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train, valid, test),\n",
    "                                                            batch_size = BATCH_SIZE, \n",
    "                                                            sort_key = lambda x: len(x.questions),\n",
    "                                                            sort_within_batch=True,\n",
    "                                                            device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:45.202713Z",
     "start_time": "2021-01-26T16:45:45.150610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freqs': Counter({'historical': 1632,\n",
       "          'reveal': 185,\n",
       "          'policing': 247,\n",
       "          'agents': 420,\n",
       "          'undertaken': 131,\n",
       "          'cross': 1318,\n",
       "          '-': 102183,\n",
       "          'police': 2163,\n",
       "          'missions': 325,\n",
       "          'many': 19224,\n",
       "          'years': 9706,\n",
       "          '(': 89076,\n",
       "          'deflem': 9,\n",
       "          ',': 624240,\n",
       "          ')': 85255,\n",
       "          '.': 325459,\n",
       "          '19th': 2675,\n",
       "          'ww2': 5,\n",
       "          'european': 5395,\n",
       "          'agencies': 650,\n",
       "          'undertook': 85,\n",
       "          'border': 1206,\n",
       "          'surveillance': 123,\n",
       "          'concerns': 679,\n",
       "          'anarchist': 20,\n",
       "          'political': 5745,\n",
       "          'notable': 1314,\n",
       "          'example': 5204,\n",
       "          'prussian': 840,\n",
       "          'karl': 340,\n",
       "          'marx': 147,\n",
       "          'remained': 2028,\n",
       "          'resident': 322,\n",
       "          'london': 3596,\n",
       "          'interests': 540,\n",
       "          'public': 6321,\n",
       "          'operation': 1217,\n",
       "          'control': 4560,\n",
       "          'radicalism': 9,\n",
       "          'ordinary': 505,\n",
       "          'law': 6526,\n",
       "          'crime': 888,\n",
       "          'primarily': 1808,\n",
       "          'initiated': 474,\n",
       "          'europe': 4590,\n",
       "          'eventually': 1925,\n",
       "          'led': 5802,\n",
       "          'establishment': 1000,\n",
       "          'interpol': 29,\n",
       "          'second': 6486,\n",
       "          'world': 13404,\n",
       "          'war': 11285,\n",
       "          'also': 26172,\n",
       "          'interesting': 106,\n",
       "          'examples': 1359,\n",
       "          'private': 2462,\n",
       "          'auspices': 104,\n",
       "          'municipal': 384,\n",
       "          'forces': 3965,\n",
       "          'date': 1649,\n",
       "          'established': 4616,\n",
       "          'modern': 5858,\n",
       "          'transgressed': 12,\n",
       "          'boundaries': 442,\n",
       "          'time': 13831,\n",
       "          'almost': 2190,\n",
       "          'inception': 137,\n",
       "          'generally': 3146,\n",
       "          'agreed': 1088,\n",
       "          'post': 2178,\n",
       "          '–': 6540,\n",
       "          'cold': 979,\n",
       "          'era': 2154,\n",
       "          'type': 3584,\n",
       "          'practice': 1478,\n",
       "          'became': 8313,\n",
       "          'significant': 2897,\n",
       "          'frequent': 399,\n",
       "          'sheptycki': 46,\n",
       "          '2000).<mos': 6,\n",
       "          '>': 81566,\n",
       "          'created': 3081,\n",
       "          'century': 12891,\n",
       "          '?': 81362,\n",
       "          'aftermath': 204,\n",
       "          '1986': 539,\n",
       "          'u.s.': 5573,\n",
       "          'attack': 1503,\n",
       "          'army': 4345,\n",
       "          'purged': 46,\n",
       "          'perceived': 621,\n",
       "          'disloyal': 4,\n",
       "          'elements': 1612,\n",
       "          '1988': 719,\n",
       "          'announced': 2294,\n",
       "          'creation': 1067,\n",
       "          'popular': 3214,\n",
       "          'militia': 299,\n",
       "          'replace': 442,\n",
       "          '1987': 510,\n",
       "          'libya': 633,\n",
       "          'began': 5615,\n",
       "          'production': 2958,\n",
       "          'mustard': 22,\n",
       "          'gas': 1167,\n",
       "          'rabta': 3,\n",
       "          '1993': 585,\n",
       "          'publicly': 416,\n",
       "          'denying': 82,\n",
       "          'stockpiling': 2,\n",
       "          'chemical': 1066,\n",
       "          'weapons': 740,\n",
       "          'unsuccessfully': 68,\n",
       "          'attempted': 833,\n",
       "          'develop': 1101,\n",
       "          'nuclear': 1121,\n",
       "          'period': 6604,\n",
       "          'saw': 2000,\n",
       "          'growth': 2278,\n",
       "          'domestic': 1317,\n",
       "          'islamist': 79,\n",
       "          'formulated': 143,\n",
       "          'groups': 4393,\n",
       "          'like': 5882,\n",
       "          'muslim': 1452,\n",
       "          'brotherhood': 148,\n",
       "          'libyan': 283,\n",
       "          'islamic': 1829,\n",
       "          'fighting': 759,\n",
       "          'group': 6375,\n",
       "          'number': 8176,\n",
       "          'assassination': 199,\n",
       "          'attempts': 711,\n",
       "          'gaddafi': 1088,\n",
       "          'foiled': 11,\n",
       "          'turn': 1334,\n",
       "          '1989': 808,\n",
       "          'security': 1853,\n",
       "          'raid': 214,\n",
       "          'mosques': 98,\n",
       "          'believed': 1530,\n",
       "          'revolutionary': 694,\n",
       "          'preaching': 146,\n",
       "          'october': 2785,\n",
       "          'although': 6406,\n",
       "          'increasingly': 996,\n",
       "          'marginalised': 2,\n",
       "          'failed': 1100,\n",
       "          'coup': 474,\n",
       "          'misrata': 45,\n",
       "          'september': 3148,\n",
       "          '1995': 666,\n",
       "          'islamists': 39,\n",
       "          'launched': 1348,\n",
       "          'insurgency': 88,\n",
       "          'benghazi': 82,\n",
       "          'july': 2815,\n",
       "          '1996': 700,\n",
       "          'anti': 1434,\n",
       "          'gaddafist': 39,\n",
       "          'football': 2876,\n",
       "          'riot': 150,\n",
       "          'broke': 675,\n",
       "          'tripoli': 74,\n",
       "          'committees': 215,\n",
       "          'experienced': 671,\n",
       "          'resurgence': 50,\n",
       "          'combat': 604,\n",
       "          'islamists.<mos': 2,\n",
       "          'take': 2784,\n",
       "          'place': 4098,\n",
       "          '2016': 519,\n",
       "          'news': 1312,\n",
       "          '&': 1608,\n",
       "          'report': 1590,\n",
       "          'byu': 820,\n",
       "          'tied': 287,\n",
       "          '66th': 4,\n",
       "          'national': 7593,\n",
       "          'universities': 1911,\n",
       "          'united': 12623,\n",
       "          'states': 13720,\n",
       "          '2013': 2758,\n",
       "          'quarterly': 47,\n",
       "          'journal': 484,\n",
       "          'economics': 390,\n",
       "          'study': 3296,\n",
       "          'nation': 1719,\n",
       "          \"'s\": 67096,\n",
       "          'top': 3124,\n",
       "          'high': 7980,\n",
       "          'school': 6482,\n",
       "          'students': 3110,\n",
       "          'choose': 422,\n",
       "          'enroll': 57,\n",
       "          '21': 1057,\n",
       "          'peer': 202,\n",
       "          'reviewed': 110,\n",
       "          'princeton': 197,\n",
       "          'review': 839,\n",
       "          'ranked': 1253,\n",
       "          'best': 2984,\n",
       "          'value': 1444,\n",
       "          'college': 3540,\n",
       "          '2007': 2660,\n",
       "          'library': 1152,\n",
       "          'consistently': 189,\n",
       "          'ten': 1510,\n",
       "          '—': 5525,\n",
       "          '1': 3841,\n",
       "          '2004': 1600,\n",
       "          '4': 1845,\n",
       "          '19': 960,\n",
       "          '\"': 104398,\n",
       "          'great': 5768,\n",
       "          'schools': 3408,\n",
       "          'prices': 597,\n",
       "          'lineup': 89,\n",
       "          '12': 1898,\n",
       "          'lowest': 629,\n",
       "          'student': 1309,\n",
       "          'incurred': 54,\n",
       "          'debt': 516,\n",
       "          'due': 4967,\n",
       "          'part': 8424,\n",
       "          'emphasis': 564,\n",
       "          'undergraduate': 458,\n",
       "          'research': 3428,\n",
       "          'rankings': 161,\n",
       "          '2009': 2929,\n",
       "          'nationally': 222,\n",
       "          'earn': 131,\n",
       "          'phds': 24,\n",
       "          'go': 1188,\n",
       "          'dental': 52,\n",
       "          '6': 1501,\n",
       "          '10': 2951,\n",
       "          'medical': 1739,\n",
       "          'designated': 497,\n",
       "          'university': 7589,\n",
       "          'activity': 1321,\n",
       "          'carnegie': 34,\n",
       "          'foundation': 1279,\n",
       "          'advancement': 108,\n",
       "          'teaching': 814,\n",
       "          ']': 6781,\n",
       "          'forbes': 276,\n",
       "          'magazine': 857,\n",
       "          'work': 5246,\n",
       "          '2014': 2460,\n",
       "          'utah.<mos': 17,\n",
       "          'utah': 173,\n",
       "          'long': 5057,\n",
       "          'rumour': 10,\n",
       "          'approved': 729,\n",
       "          'british': 6800,\n",
       "          'government': 9660,\n",
       "          'plans': 791,\n",
       "          'construct': 193,\n",
       "          'airport': 1821,\n",
       "          'saint': 1562,\n",
       "          'helena': 400,\n",
       "          'march': 3030,\n",
       "          '2005': 2069,\n",
       "          'expected': 935,\n",
       "          'completed': 1045,\n",
       "          '2010': 3140,\n",
       "          'however': 9227,\n",
       "          'bidder': 22,\n",
       "          'italian': 1761,\n",
       "          'firm': 385,\n",
       "          'impregilo': 5,\n",
       "          'chosen': 692,\n",
       "          '2008': 2881,\n",
       "          'project': 1348,\n",
       "          'put': 1351,\n",
       "          'hold': 1091,\n",
       "          'allegedly': 151,\n",
       "          'new': 20267,\n",
       "          'financial': 2035,\n",
       "          'pressures': 153,\n",
       "          'brought': 2099,\n",
       "          'crisis': 1069,\n",
       "          '2007–2010': 4,\n",
       "          'january': 2878,\n",
       "          'commenced': 92,\n",
       "          'final': 2069,\n",
       "          'contracts': 196,\n",
       "          'signed': 1231,\n",
       "          'governor': 1535,\n",
       "          'andrew': 331,\n",
       "          'gurr': 17,\n",
       "          'departed': 103,\n",
       "          'attempt': 1059,\n",
       "          'speed': 1613,\n",
       "          'process': 3510,\n",
       "          'solve': 162,\n",
       "          'problems.<mos': 43,\n",
       "          'consultation': 124,\n",
       "          'arrived': 689,\n",
       "          'paris': 2287,\n",
       "          'late': 4660,\n",
       "          'fully': 847,\n",
       "          ';': 22518,\n",
       "          'would': 11073,\n",
       "          'never': 1952,\n",
       "          'return': 1591,\n",
       "          'poland': 858,\n",
       "          'thus': 2853,\n",
       "          'becoming': 1193,\n",
       "          'one': 22696,\n",
       "          'expatriates': 50,\n",
       "          'polish': 1145,\n",
       "          'emigration': 145,\n",
       "          'france': 4117,\n",
       "          'used': 15412,\n",
       "          'french': 6014,\n",
       "          'versions': 797,\n",
       "          'names': 1150,\n",
       "          'receiving': 479,\n",
       "          'citizenship': 284,\n",
       "          '1835': 188,\n",
       "          'travelled': 194,\n",
       "          'chopin': 1395,\n",
       "          'fellow': 298,\n",
       "          'poles': 306,\n",
       "          'exile': 355,\n",
       "          'friends': 585,\n",
       "          'confidants': 11,\n",
       "          'felt': 600,\n",
       "          '1831': 88,\n",
       "          'comfortable': 74,\n",
       "          'speaking': 1293,\n",
       "          'biographer': 77,\n",
       "          'zamoyski': 25,\n",
       "          'writes': 452,\n",
       "          'considered': 4656,\n",
       "          'father': 1698,\n",
       "          'origins': 577,\n",
       "          'always': 1370,\n",
       "          'pole.<mos': 24,\n",
       "          'going': 650,\n",
       "          'certain': 2248,\n",
       "          'christian': 2276,\n",
       "          'jewish': 2244,\n",
       "          'among': 5577,\n",
       "          'others': 3047,\n",
       "          'espousing': 5,\n",
       "          'ideas': 1325,\n",
       "          'deemed': 328,\n",
       "          'heretical': 106,\n",
       "          'subjected': 128,\n",
       "          'discipline': 399,\n",
       "          'punishments': 71,\n",
       "          'even': 4884,\n",
       "          'death': 3739,\n",
       "          'penalty.<mos': 4,\n",
       "          'cultures': 966,\n",
       "          'merely': 503,\n",
       "          'heretic': 76,\n",
       "          'large': 6580,\n",
       "          'diverse': 768,\n",
       "          'lineage': 147,\n",
       "          'short': 2028,\n",
       "          'tailed': 50,\n",
       "          'avialans': 21,\n",
       "          'evolve': 183,\n",
       "          'enantiornithes': 20,\n",
       "          'opposite': 415,\n",
       "          'birds': 1477,\n",
       "          'sand': 483,\n",
       "          'construction': 1702,\n",
       "          'shoulder': 69,\n",
       "          'bones': 197,\n",
       "          'reverse': 383,\n",
       "          'occupied': 931,\n",
       "          'array': 197,\n",
       "          'ecological': 158,\n",
       "          'niches': 83,\n",
       "          'named': 2534,\n",
       "          'probing': 15,\n",
       "          'shorebirds': 15,\n",
       "          'fish': 545,\n",
       "          'eaters': 15,\n",
       "          'tree': 757,\n",
       "          'dwelling': 104,\n",
       "          'forms': 2507,\n",
       "          'seed': 249,\n",
       "          'dominant': 937,\n",
       "          'cretaceous': 354,\n",
       "          'along': 4701,\n",
       "          'dinosaur': 56,\n",
       "          'end': 5364,\n",
       "          'mesozoic': 92,\n",
       "          'era.<mos': 76,\n",
       "          'traditionally': 955,\n",
       "          'speaker': 521,\n",
       "          'house': 4869,\n",
       "          'leader': 1914,\n",
       "          'majority': 2710,\n",
       "          'party': 4922,\n",
       "          'command': 1052,\n",
       "          'instance': 977,\n",
       "          'republicans': 336,\n",
       "          'gained': 1107,\n",
       "          'elections': 1044,\n",
       "          'eric': 122,\n",
       "          'cantor': 19,\n",
       "          'succeeded': 536,\n",
       "          'boehner': 25,\n",
       "          'despite': 1940,\n",
       "          'successor': 478,\n",
       "          'kevin': 122,\n",
       "          'mccarthy': 51,\n",
       "          'reckoned': 59,\n",
       "          'ranking': 430,\n",
       "          'since': 8357,\n",
       "          'exceptions': 324,\n",
       "          'recent': 1895,\n",
       "          'exception': 620,\n",
       "          'rule': 2877,\n",
       "          'came': 2997,\n",
       "          'tom': 430,\n",
       "          'delay': 230,\n",
       "          'overshadowed': 29,\n",
       "          'dennis': 91,\n",
       "          'hastert': 19,\n",
       "          '2003': 1390,\n",
       "          'contrast': 995,\n",
       "          'minority': 1484,\n",
       "          'party.<mos': 78,\n",
       "          'city': 17610,\n",
       "          'planned': 922,\n",
       "          'specific': 1753,\n",
       "          'areas': 4359,\n",
       "          'everything': 316,\n",
       "          'accommodation': 95,\n",
       "          'hotels': 267,\n",
       "          'sectors': 257,\n",
       "          'north': 7929,\n",
       "          'south': 7248,\n",
       "          'hotel': 484,\n",
       "          'facilities': 771,\n",
       "          'developed': 4381,\n",
       "          'tourism': 667,\n",
       "          'sector': 904,\n",
       "          'shores': 127,\n",
       "          'lake': 856,\n",
       "          'paranoá': 33,\n",
       "          'including': 9233,\n",
       "          'brasília': 291,\n",
       "          'range': 2565,\n",
       "          'inns': 55,\n",
       "          'pensions': 39,\n",
       "          'hostels': 8,\n",
       "          'larger': 1792,\n",
       "          'international': 5604,\n",
       "          'chain': 658,\n",
       "          'restaurants': 436,\n",
       "          'cater': 77,\n",
       "          'wide': 1397,\n",
       "          'foods': 288,\n",
       "          'local': 4088,\n",
       "          'regional': 1610,\n",
       "          'brazilian': 233,\n",
       "          'dishes': 185,\n",
       "          'placed': 1213,\n",
       "          'brasilia': 63,\n",
       "          'beginning': 2115,\n",
       "          'han': 1088,\n",
       "          'dynasty': 1737,\n",
       "          'every': 2830,\n",
       "          'male': 886,\n",
       "          'commoner': 34,\n",
       "          'aged': 295,\n",
       "          'three': 8176,\n",
       "          'liable': 29,\n",
       "          'conscription': 92,\n",
       "          'military': 4793,\n",
       "          'minimum': 504,\n",
       "          'age': 3165,\n",
       "          'draft': 296,\n",
       "          'reduced': 1197,\n",
       "          'twenty': 577,\n",
       "          'emperor': 2187,\n",
       "          'zhao': 26,\n",
       "          'r.': 640,\n",
       "          '87–74': 3,\n",
       "          'bc': 2850,\n",
       "          'year': 11129,\n",
       "          'conscripted': 53,\n",
       "          'soldiers': 1052,\n",
       "          'underwent': 192,\n",
       "          'training': 1367,\n",
       "          'service': 3768,\n",
       "          'non': 5026,\n",
       "          'branches': 521,\n",
       "          'armed': 1052,\n",
       "          ':': 13651,\n",
       "          'cavalry': 297,\n",
       "          'navy': 1118,\n",
       "          'reign': 844,\n",
       "          'active': 1621,\n",
       "          'served': 1526,\n",
       "          'either': 2650,\n",
       "          'frontier': 228,\n",
       "          'king': 3818,\n",
       "          'court': 4395,\n",
       "          'minister': 2002,\n",
       "          'guards': 176,\n",
       "          'capital': 2908,\n",
       "          'small': 4257,\n",
       "          'professional': 1287,\n",
       "          'paid': 779,\n",
       "          'standing': 635,\n",
       "          'stationed': 168,\n",
       "          'near': 3024,\n",
       "          'capital.<mos': 39,\n",
       "          'could': 5772,\n",
       "          'soldier': 123,\n",
       "          'expect': 162,\n",
       "          'another': 4968,\n",
       "          'issue': 1338,\n",
       "          'use': 10229,\n",
       "          'hypopodium': 7,\n",
       "          'platform': 498,\n",
       "          'support': 3871,\n",
       "          'feet': 788,\n",
       "          'given': 2886,\n",
       "          'hands': 562,\n",
       "          'may': 13172,\n",
       "          'able': 1851,\n",
       "          'foot': 371,\n",
       "          '17th': 805,\n",
       "          'rasmus': 9,\n",
       "          'bartholin': 10,\n",
       "          'analytical': 92,\n",
       "          'scenarios': 39,\n",
       "          'topic': 176,\n",
       "          '20th': 2242,\n",
       "          'forensic': 91,\n",
       "          'pathologist': 18,\n",
       "          'frederick': 562,\n",
       "          'zugibe': 21,\n",
       "          'performed': 1117,\n",
       "          'crucifixion': 287,\n",
       "          'experiments': 370,\n",
       "          'using': 3855,\n",
       "          'ropes': 71,\n",
       "          'hang': 67,\n",
       "          'human': 4532,\n",
       "          'subjects': 674,\n",
       "          'various': 3753,\n",
       "          'angles': 102,\n",
       "          'hand': 1415,\n",
       "          'positions': 650,\n",
       "          'angled': 54,\n",
       "          'suspension': 94,\n",
       "          'two': 15163,\n",
       "          'perhaps': 783,\n",
       "          'form': 6079,\n",
       "          'weight': 625,\n",
       "          'aufbinden': 6,\n",
       "          'straight': 159,\n",
       "          'stake': 231,\n",
       "          'nazis': 90,\n",
       "          'dachau': 6,\n",
       "          'ii': 2986,\n",
       "          'rather': 2843,\n",
       "          'quickly.<mos': 14,\n",
       "          'said': 2973,\n",
       "          'solar': 1373,\n",
       "          'energy': 4518,\n",
       "          'water': 3924,\n",
       "          'stabilisation': 4,\n",
       "          'pond': 54,\n",
       "          'treat': 202,\n",
       "          'waste': 374,\n",
       "          'without': 3748,\n",
       "          'chemicals': 280,\n",
       "          'electricity': 647,\n",
       "          'environmental': 934,\n",
       "          'algae': 127,\n",
       "          'grow': 632,\n",
       "          'ponds': 38,\n",
       "          'consume': 101,\n",
       "          'carbon': 754,\n",
       "          'dioxide': 197,\n",
       "          'photosynthesis': 130,\n",
       "          'produce': 1676,\n",
       "          'make': 3399,\n",
       "          'reason': 1165,\n",
       "          'toxic': 264,\n",
       "          'gut': 185,\n",
       "          'tube': 233,\n",
       "          'supported': 1434,\n",
       "          'vertical': 357,\n",
       "          'within': 5931,\n",
       "          'segments': 357,\n",
       "          'ends': 349,\n",
       "          'anus': 48,\n",
       "          'underside': 26,\n",
       "          'pygidium': 21,\n",
       "          'members': 4252,\n",
       "          'family': 3357,\n",
       "          'siboglinidae': 11,\n",
       "          'blocked': 174,\n",
       "          'swollen': 20,\n",
       "          'lining': 53,\n",
       "          'houses': 1210,\n",
       "          'symbiotic': 96,\n",
       "          '15': 2017,\n",
       "          '%': 14766,\n",
       "          'annelids': 292,\n",
       "          \"'\": 13190,\n",
       "          'total': 2916,\n",
       "          'bacteria': 1161,\n",
       "          'convert': 306,\n",
       "          'inorganic': 54,\n",
       "          'matter': 1595,\n",
       "          'hydrogen': 687,\n",
       "          'sulfide': 85,\n",
       "          'hydrothermal': 15,\n",
       "          'vents': 15,\n",
       "          'methane': 140,\n",
       "          'organic': 463,\n",
       "          'feeds': 58,\n",
       "          'hosts': 515,\n",
       "          'worms': 161,\n",
       "          'extend': 358,\n",
       "          'palps': 21,\n",
       "          'flows': 256,\n",
       "          'absorb': 148,\n",
       "          'gases': 103,\n",
       "          'needed': 3343,\n",
       "          'bacteria.<mos': 30,\n",
       "          'different': 5318,\n",
       "          'patterns': 613,\n",
       "          'occurs': 745,\n",
       "          'exchange': 891,\n",
       "          'demonstrated': 588,\n",
       "          'insects': 942,\n",
       "          'continuous': 435,\n",
       "          'diffusive': 11,\n",
       "          'ventilation': 46,\n",
       "          'discontinuous': 32,\n",
       "          'exchange.:65–68': 5,\n",
       "          'oxygen': 495,\n",
       "          'taken': 1707,\n",
       "          'released': 3262,\n",
       "          'cycle': 510,\n",
       "          'insect': 407,\n",
       "          'takes': 779,\n",
       "          'amounts': 540,\n",
       "          'rest': 1401,\n",
       "          'simply': 950,\n",
       "          'physically': 142,\n",
       "          'taking': 1055,\n",
       "          'species': 4367,\n",
       "          'submerged': 46,\n",
       "          'adaptations': 162,\n",
       "          'aid': 905,\n",
       "          'respiration': 34,\n",
       "          'larvae': 87,\n",
       "          'gills': 15,\n",
       "          'extract': 138,\n",
       "          'dissolved': 294,\n",
       "          'need': 1251,\n",
       "          'rise': 1592,\n",
       "          'surface': 1329,\n",
       "          'replenish': 56,\n",
       "          'air': 4220,\n",
       "          'supplies': 326,\n",
       "          'held': 3697,\n",
       "          'trapped': 85,\n",
       "          'special': 1928,\n",
       "          'structures.<mos': 30,\n",
       "          'contain': 1009,\n",
       "          'widely': 1876,\n",
       "          'spoken': 1331,\n",
       "          'languages': 3172,\n",
       "          'southern': 3334,\n",
       "          'romance': 365,\n",
       "          'heirs': 72,\n",
       "          'latin': 2380,\n",
       "          'spread': 1457,\n",
       "          'peninsula': 830,\n",
       "          'emblematic': 30,\n",
       "          'galician': 124,\n",
       "          'see': 2627,\n",
       "          'arch': 210,\n",
       "          'far': 2252,\n",
       "          'common': 5050,\n",
       "          '50': 1374,\n",
       "          'million': 7572,\n",
       "          'people': 10452,\n",
       "          'italy': 1681,\n",
       "          'san': 2283,\n",
       "          'marino': 16,\n",
       "          'spanish': 2554,\n",
       "          '40': 1239,\n",
       "          'spain': 1339,\n",
       "          'gibraltar': 67,\n",
       "          'include': 5994,\n",
       "          'romanian': 86,\n",
       "          'romania': 232,\n",
       "          'moldova': 53,\n",
       "          'portuguese': 1102,\n",
       "          'portugal': 920,\n",
       "          'catalan': 517,\n",
       "          'eastern': 3601,\n",
       "          'northwestern': 964,\n",
       "          'spain.<mos': 27,\n",
       "          'speak': 688,\n",
       "          'found': 5711,\n",
       "          'oklahoma': 1015,\n",
       "          'major': 7082,\n",
       "          'stockyards': 4,\n",
       "          'attracting': 172,\n",
       "          'jobs': 552,\n",
       "          'revenue': 738,\n",
       "          'capitol': 164,\n",
       "          'chicago': 1113,\n",
       "          'omaha': 37,\n",
       "          'nebraska': 128,\n",
       "          'discovery': 846,\n",
       "          'oil': 1687,\n",
       "          'limits': 569,\n",
       "          'state': 13536,\n",
       "          'formerly': 752,\n",
       "          'center': 3363,\n",
       "          'accompanied': 508,\n",
       "          'interstate': 388,\n",
       "          'system': 9468,\n",
       "          'interchange': 26,\n",
       "          'convergence': 63,\n",
       "          'i-40': 10,\n",
       "          'i-44': 3,\n",
       "          'aided': 227,\n",
       "          'federal': 4349,\n",
       "          'development': 4867,\n",
       "          'tinker': 21,\n",
       "          'force': 3327,\n",
       "          'base.<mos': 10,\n",
       "          'discovered': 1250,\n",
       "          'term': 5178,\n",
       "          'punk': 978,\n",
       "          'first': 21808,\n",
       "          '1970s': 1003,\n",
       "          'describe': 871,\n",
       "          'moving': 737,\n",
       "          'beyond': 1128,\n",
       "          'sonic': 58,\n",
       "          'template': 38,\n",
       "          'disparate': 50,\n",
       "          'artists': 1409,\n",
       "          'initially': 1369,\n",
       "          'diy': 36,\n",
       "          'ethic': 34,\n",
       "          'ultimately': 720,\n",
       "          'disillusioned': 29,\n",
       "          'style': 2711,\n",
       "          'movement': 2341,\n",
       "          'commercial': 2017,\n",
       "          'formula': 281,\n",
       "          'rock': 2475,\n",
       "          'convention': 934,\n",
       "          'parody': 33,\n",
       "          'repudiated': 29,\n",
       "          'populist': 47,\n",
       "          'claims': 746,\n",
       "          'accessibility': 24,\n",
       "          'raw': 301,\n",
       "          'simplicity': 68,\n",
       "          'instead': 2243,\n",
       "          'seeing': 239,\n",
       "          'opportunity': 476,\n",
       "          'break': 711,\n",
       "          'musical': 1117,\n",
       "          'tradition': 1428,\n",
       "          'focus': 1116,\n",
       "          'commonplaces': 9,\n",
       "          'challenge': 474,\n",
       "          'audiences': 212,\n",
       "          'moved': 1583,\n",
       "          'beyonds': 11,\n",
       "          'subvert': 24,\n",
       "          'largely': 1676,\n",
       "          'white': 3483,\n",
       "          'working': 1716,\n",
       "          'class': 2450,\n",
       "          'population': 7339,\n",
       "          'abandoned': 537,\n",
       "          'continued': 2927,\n",
       "          'roll': 212,\n",
       "          'tropes': 25,\n",
       "          'chord': 48,\n",
       "          'chuck': 32,\n",
       "          'berry': 40,\n",
       "          'based': 6816,\n",
       "          'guitar': 266,\n",
       "          'riffs': 61,\n",
       "          'defined': 1493,\n",
       "          'imperative': 68,\n",
       "          'constant': 773,\n",
       "          'change': 2449,\n",
       "          'believing': 193,\n",
       "          'radical': 471,\n",
       "          'content': 1287,\n",
       "          'demands': 278,\n",
       "          'form\".<mos': 10,\n",
       "          'coined': 255,\n",
       "          'frances': 31,\n",
       "          'a.': 414,\n",
       "          'm.': 438,\n",
       "          'patriarch': 169,\n",
       "          'alexander': 917,\n",
       "          'bed': 183,\n",
       "          'called': 8894,\n",
       "          'athanasius': 852,\n",
       "          'fearing': 127,\n",
       "          'constrained': 56,\n",
       "          'made': 8513,\n",
       "          'bishop': 628,\n",
       "          'bishops': 538,\n",
       "          'church': 6014,\n",
       "          'assembled': 236,\n",
       "          'elect': 186,\n",
       "          'whole': 1011,\n",
       "          'catholic': 2225,\n",
       "          'surrounded': 353,\n",
       "          'holding': 448,\n",
       "          'heaven': 228,\n",
       "          'crying': 38,\n",
       "          'give': 1235,\n",
       "          '!': 504,\n",
       "          'us': 3758,\n",
       "          'nothing': 510,\n",
       "          'better': 1275,\n",
       "          'elected': 1597,\n",
       "          'gregory': 199,\n",
       "          'tells': 99,\n",
       "          'pope': 1547,\n",
       "          'full': 2024,\n",
       "          'access': 1662,\n",
       "          'vatican': 333,\n",
       "          'archives).<mos': 10,\n",
       "          'want': 508,\n",
       "          'tonnage': 56,\n",
       "          'levels': 1661,\n",
       "          'port': 1571,\n",
       "          'decreased': 431,\n",
       "          'shipping': 408,\n",
       "          'activities': 1156,\n",
       "          'suspended': 309,\n",
       "          'economic': 3065,\n",
       "          'benefits': 449,\n",
       "          'petrochemical': 41,\n",
       "          'refineries': 76,\n",
       "          'manufacturing': 792,\n",
       "          'plants': 2095,\n",
       "          'ship': 712,\n",
       "          'channel': 1061,\n",
       "          'demand': 592,\n",
       "          'petroleum': 303,\n",
       "          'synthetic': 388,\n",
       "          'rubber': 169,\n",
       "          'defense': 930,\n",
       "          'industry': 2158,\n",
       "          'field': 2610,\n",
       "          'built': 3354,\n",
       "          'revitalized': 36,\n",
       "          'advanced': 864,\n",
       "          'bombardiers': 14,\n",
       "          'navigators': 32,\n",
       "          'brown': 732,\n",
       "          'shipbuilding': 106,\n",
       "          'company': 5140,\n",
       "          'founded': 2529,\n",
       "          'build': 687,\n",
       "          'ships': 954,\n",
       "          'boom': 301,\n",
       "          'thousands': 993,\n",
       "          'workers': 754,\n",
       "          'migrated': 295,\n",
       "          'whites': 422,\n",
       "          'competing': 333,\n",
       "          'paying': 195,\n",
       "          'president': 4691,\n",
       "          'roosevelt': 309,\n",
       "          'policy': 2070,\n",
       "          'discrimination': 555,\n",
       "          'opportunities': 348,\n",
       "          'contractors': 98,\n",
       "          'blacks': 489,\n",
       "          'resistance': 1262,\n",
       "          'increasing': 1288,\n",
       "          'social': 4183,\n",
       "          'tensions': 322,\n",
       "          'erupted': 81,\n",
       "          'occasional': 204,\n",
       "          'violence': 444,\n",
       "          'gains': 141,\n",
       "          'entered': 874,\n",
       "          'industries': 660,\n",
       "          'years.<mos': 341,\n",
       "          'fill': 251,\n",
       "          'T': 126,\n",
       "          'york': 3600,\n",
       "          'home': 4216,\n",
       "          'headquarters': 875,\n",
       "          'league': 4538,\n",
       "          'baseball': 340,\n",
       "          'basketball': 493,\n",
       "          'association': 1984,\n",
       "          'hockey': 362,\n",
       "          'soccer': 196,\n",
       "          'metropolitan': 1092,\n",
       "          'area': 6856,\n",
       "          'sports': 1306,\n",
       "          'teams': 1679,\n",
       "          'five': 3923,\n",
       "          'leagues': 287,\n",
       "          'participation': 301,\n",
       "          'predates': 19,\n",
       "          'continuously': 276,\n",
       "          'hosting': 178,\n",
       "          'birth': 1024,\n",
       "          'brooklyn': 243,\n",
       "          'dodgers': 30,\n",
       "          '1882': 168,\n",
       "          'played': 2457,\n",
       "          'host': 984,\n",
       "          'respective': 365,\n",
       "          'current': 3007,\n",
       "          'historic': 951,\n",
       "          'four': 5009,\n",
       "          'expensive': 717,\n",
       "          'stadiums': 149,\n",
       "          'ever': 1375,\n",
       "          'worldwide': 1299,\n",
       "          'metlife': 8,\n",
       "          'stadium': 1048,\n",
       "          'yankee': 52,\n",
       "          'madison': 349,\n",
       "          'square': 1871,\n",
       "          'garden': 569,\n",
       "          'predecessor': 233,\n",
       "          'well': 8424,\n",
       "          'original': 3126,\n",
       "          'ebbets': 4,\n",
       "          'famous': 1543,\n",
       "          'sporting': 155,\n",
       "          'venues': 262,\n",
       "          'latter': 1276,\n",
       "          'postage': 34,\n",
       "          'stamps.<mos': 7,\n",
       "          'located': 3733,\n",
       "          'nyc': 79,\n",
       "          'animal': 995,\n",
       "          'domestication': 139,\n",
       "          'relatively': 1439,\n",
       "          'widespread': 1036,\n",
       "          'agriculture': 819,\n",
       "          'hunting': 1515,\n",
       "          'usually': 3862,\n",
       "          'food': 2198,\n",
       "          'supply': 994,\n",
       "          'supplementary': 69,\n",
       "          'meat': 522,\n",
       "          'materials': 1056,\n",
       "          'included': 3374,\n",
       "          'protein': 469,\n",
       "          'bone': 174,\n",
       "          'implements': 51,\n",
       "          'cordage': 11,\n",
       "          'fur': 140,\n",
       "          'feathers': 165,\n",
       "          'rawhide': 9,\n",
       "          'leather': 105,\n",
       "          'clothing': 885,\n",
       "          'man': 1822,\n",
       "          'earliest': 1472,\n",
       "          'rocks': 269,\n",
       "          'spears': 41,\n",
       "          'hunt': 289,\n",
       "          'bows': 36,\n",
       "          'arrows': 84,\n",
       "          'vital': 223,\n",
       "          'marginal': 88,\n",
       "          'climates': 134,\n",
       "          'especially': 2971,\n",
       "          'pastoral': 112,\n",
       "          'uses': 1546,\n",
       "          'inuit': 49,\n",
       "          'arctic': 260,\n",
       "          'trap': 87,\n",
       "          'atlatl': 5,\n",
       "          'animals': 1572,\n",
       "          'skins': 75,\n",
       "          ...}),\n",
       " 'itos': ['<unk>',\n",
       "  '<pad>',\n",
       "  '<sos>',\n",
       "  '<eos>',\n",
       "  ',',\n",
       "  '.',\n",
       "  '\"',\n",
       "  '-',\n",
       "  '(',\n",
       "  ')',\n",
       "  '>',\n",
       "  '?',\n",
       "  \"'s\",\n",
       "  'is',\n",
       "  'impossilbe',\n",
       "  'also',\n",
       "  'one',\n",
       "  ';',\n",
       "  'first',\n",
       "  'new',\n",
       "  'many',\n",
       "  'city',\n",
       "  'used',\n",
       "  'two',\n",
       "  '%',\n",
       "  'time',\n",
       "  'states',\n",
       "  ':',\n",
       "  'state',\n",
       "  'world',\n",
       "  \"'\",\n",
       "  'may',\n",
       "  'century',\n",
       "  'united',\n",
       "  'war',\n",
       "  'year',\n",
       "  'would',\n",
       "  'the',\n",
       "  'known',\n",
       "  'people',\n",
       "  'use',\n",
       "  'years',\n",
       "  'government',\n",
       "  'system',\n",
       "  'including',\n",
       "  'however',\n",
       "  'early',\n",
       "  'called',\n",
       "  'made',\n",
       "  'part',\n",
       "  'well',\n",
       "  'since',\n",
       "  'became',\n",
       "  'number',\n",
       "  'three',\n",
       "  'high',\n",
       "  'later',\n",
       "  'north',\n",
       "  'american',\n",
       "  'often',\n",
       "  'national',\n",
       "  'university',\n",
       "  'million',\n",
       "  'power',\n",
       "  'population',\n",
       "  'south',\n",
       "  'major',\n",
       "  'music',\n",
       "  'area',\n",
       "  'based',\n",
       "  'british',\n",
       "  ']',\n",
       "  'several',\n",
       "  'language',\n",
       "  'period',\n",
       "  'large',\n",
       "  '–',\n",
       "  'law',\n",
       "  'second',\n",
       "  'school',\n",
       "  'west',\n",
       "  'name',\n",
       "  'although',\n",
       "  'group',\n",
       "  'much',\n",
       "  'public',\n",
       "  'of',\n",
       "  'country',\n",
       "  'form',\n",
       "  'largest',\n",
       "  'church',\n",
       "  'french',\n",
       "  'include',\n",
       "  'within',\n",
       "  'like',\n",
       "  'modern',\n",
       "  'around',\n",
       "  'led',\n",
       "  'could',\n",
       "  'great',\n",
       "  'political',\n",
       "  'and',\n",
       "  'found',\n",
       "  'general',\n",
       "  'east',\n",
       "  'began',\n",
       "  'international',\n",
       "  'among',\n",
       "  'u.s.',\n",
       "  '—',\n",
       "  '/',\n",
       "  'day',\n",
       "  'english',\n",
       "  'european',\n",
       "  'according',\n",
       "  'john',\n",
       "  'end',\n",
       "  'different',\n",
       "  'work',\n",
       "  'example',\n",
       "  'empire',\n",
       "  'term',\n",
       "  'german',\n",
       "  'company',\n",
       "  'long',\n",
       "  'common',\n",
       "  'non',\n",
       "  'four',\n",
       "  'another',\n",
       "  'due',\n",
       "  'party',\n",
       "  'even',\n",
       "  'house',\n",
       "  'development',\n",
       "  'countries',\n",
       "  'military',\n",
       "  'greek',\n",
       "  'still',\n",
       "  '$',\n",
       "  'following',\n",
       "  'along',\n",
       "  'president',\n",
       "  'late',\n",
       "  'considered',\n",
       "  'established',\n",
       "  'europe',\n",
       "  'control',\n",
       "  'league',\n",
       "  'human',\n",
       "  'energy',\n",
       "  'roman',\n",
       "  'central',\n",
       "  'western',\n",
       "  'life',\n",
       "  'chinese',\n",
       "  'important',\n",
       "  'court',\n",
       "  'groups',\n",
       "  'region',\n",
       "  'developed',\n",
       "  'species',\n",
       "  'areas',\n",
       "  'federal',\n",
       "  'become',\n",
       "  'army',\n",
       "  'de',\n",
       "  'order',\n",
       "  'small',\n",
       "  'members',\n",
       "  'air',\n",
       "  'home',\n",
       "  '°',\n",
       "  'social',\n",
       "  'china',\n",
       "  'france',\n",
       "  'history',\n",
       "  'place',\n",
       "  'local',\n",
       "  'union',\n",
       "  'film',\n",
       "  'island',\n",
       "  'forces',\n",
       "  'water',\n",
       "  'five',\n",
       "  'old',\n",
       "  'support',\n",
       "  'usually',\n",
       "  'using',\n",
       "  '1',\n",
       "  'god',\n",
       "  'king',\n",
       "  'times',\n",
       "  'service',\n",
       "  'light',\n",
       "  'though',\n",
       "  'us',\n",
       "  'various',\n",
       "  'without',\n",
       "  'death',\n",
       "  'located',\n",
       "  'held',\n",
       "  'per',\n",
       "  'set',\n",
       "  'religious',\n",
       "  'season',\n",
       "  'act',\n",
       "  'less',\n",
       "  'eastern',\n",
       "  'york',\n",
       "  'london',\n",
       "  'third',\n",
       "  'type',\n",
       "  'india',\n",
       "  'college',\n",
       "  'process',\n",
       "  'middle',\n",
       "  'england',\n",
       "  'land',\n",
       "  'white',\n",
       "  'main',\n",
       "  'northern',\n",
       "  'soviet',\n",
       "  'last',\n",
       "  'research',\n",
       "  'schools',\n",
       "  'education',\n",
       "  'make',\n",
       "  'back',\n",
       "  'kingdom',\n",
       "  'included',\n",
       "  'royal',\n",
       "  'standard',\n",
       "  'center',\n",
       "  'family',\n",
       "  'built',\n",
       "  'needed',\n",
       "  'southern',\n",
       "  'force',\n",
       "  'study',\n",
       "  'game',\n",
       "  'way',\n",
       "  'single',\n",
       "  'released',\n",
       "  'germany',\n",
       "  'culture',\n",
       "  'popular',\n",
       "  'britain',\n",
       "  'free',\n",
       "  'systems',\n",
       "  'black',\n",
       "  'languages',\n",
       "  'age',\n",
       "  'similar',\n",
       "  'building',\n",
       "  'september',\n",
       "  'generally',\n",
       "  '2010',\n",
       "  'took',\n",
       "  'america',\n",
       "  'low',\n",
       "  'result',\n",
       "  'original',\n",
       "  'top',\n",
       "  'red',\n",
       "  'students',\n",
       "  'created',\n",
       "  'former',\n",
       "  'produced',\n",
       "  'economic',\n",
       "  'river',\n",
       "  'others',\n",
       "  'council',\n",
       "  'march',\n",
       "  'near',\n",
       "  'higher',\n",
       "  'republic',\n",
       "  'current',\n",
       "  'came',\n",
       "  '2',\n",
       "  'ii',\n",
       "  'best',\n",
       "  'line',\n",
       "  'said',\n",
       "  'especially',\n",
       "  'art',\n",
       "  'production',\n",
       "  'june',\n",
       "  'throughout',\n",
       "  '10',\n",
       "  '2009',\n",
       "  'continued',\n",
       "  'level',\n",
       "  'total',\n",
       "  '3',\n",
       "  'capital',\n",
       "  'body',\n",
       "  'significant',\n",
       "  'given',\n",
       "  '2008',\n",
       "  'january',\n",
       "  'rule',\n",
       "  'football',\n",
       "  'team',\n",
       "  'sea',\n",
       "  'rights',\n",
       "  'thus',\n",
       "  'bc',\n",
       "  'sometimes',\n",
       "  'rather',\n",
       "  'today',\n",
       "  'average',\n",
       "  'every',\n",
       "  'formed',\n",
       "  'official',\n",
       "  'children',\n",
       "  'african',\n",
       "  'july',\n",
       "  'al',\n",
       "  'parts',\n",
       "  'queen',\n",
       "  'october',\n",
       "  'take',\n",
       "  '2011',\n",
       "  'science',\n",
       "  '2013',\n",
       "  'book',\n",
       "  'data',\n",
       "  'must',\n",
       "  'russian',\n",
       "  'natural',\n",
       "  'style',\n",
       "  'majority',\n",
       "  'cities',\n",
       "  'women',\n",
       "  'series',\n",
       "  'december',\n",
       "  'influence',\n",
       "  '19th',\n",
       "  ' ',\n",
       "  '2007',\n",
       "  'theory',\n",
       "  'addition',\n",
       "  'either',\n",
       "  'cultural',\n",
       "  'available',\n",
       "  'case',\n",
       "  'see',\n",
       "  '2012',\n",
       "  'battle',\n",
       "  'word',\n",
       "  'field',\n",
       "  'highest',\n",
       "  'point',\n",
       "  'traditional',\n",
       "  'men',\n",
       "  'trade',\n",
       "  'range',\n",
       "  'particularly',\n",
       "  'present',\n",
       "  'spanish',\n",
       "  'november',\n",
       "  'days',\n",
       "  '20',\n",
       "  'named',\n",
       "  'founded',\n",
       "  'half',\n",
       "  'written',\n",
       "  'ancient',\n",
       "  'increased',\n",
       "  'forms',\n",
       "  'percent',\n",
       "  'left',\n",
       "  'role',\n",
       "  'office',\n",
       "  'show',\n",
       "  'games',\n",
       "  'across',\n",
       "  'published',\n",
       "  'a',\n",
       "  'rock',\n",
       "  'civil',\n",
       "  'billion',\n",
       "  'works',\n",
       "  'record',\n",
       "  'private',\n",
       "  'society',\n",
       "  '2014',\n",
       "  'making',\n",
       "  'played',\n",
       "  'to',\n",
       "  'club',\n",
       "  'class',\n",
       "  'change',\n",
       "  'terms',\n",
       "  'market',\n",
       "  'live',\n",
       "  'services',\n",
       "  'introduced',\n",
       "  'received',\n",
       "  'april',\n",
       "  '2006',\n",
       "  'africa',\n",
       "  'community',\n",
       "  'information',\n",
       "  'lower',\n",
       "  'august',\n",
       "  'japanese',\n",
       "  'park',\n",
       "  'upon',\n",
       "  'latin',\n",
       "  'victoria',\n",
       "  'video',\n",
       "  'foreign',\n",
       "  'movement',\n",
       "  'c',\n",
       "  'islands',\n",
       "  'george',\n",
       "  'associated',\n",
       "  'provide',\n",
       "  'rate',\n",
       "  'announced',\n",
       "  'street',\n",
       "  'paris',\n",
       "  'department',\n",
       "  'constitution',\n",
       "  'san',\n",
       "  'green',\n",
       "  'growth',\n",
       "  'christian',\n",
       "  'independent',\n",
       "  'television',\n",
       "  'nations',\n",
       "  'events',\n",
       "  'least',\n",
       "  'records',\n",
       "  'primary',\n",
       "  'far',\n",
       "  'certain',\n",
       "  'thought',\n",
       "  'jewish',\n",
       "  'instead',\n",
       "  '20th',\n",
       "  '5',\n",
       "  'february',\n",
       "  'media',\n",
       "  'self',\n",
       "  'catholic',\n",
       "  'six',\n",
       "  'windows',\n",
       "  'model',\n",
       "  'treaty',\n",
       "  '8',\n",
       "  'indian',\n",
       "  'in',\n",
       "  'food',\n",
       "  'health',\n",
       "  'followed',\n",
       "  'almost',\n",
       "  'emperor',\n",
       "  '[',\n",
       "  'play',\n",
       "  'side',\n",
       "  'post',\n",
       "  'color',\n",
       "  'canada',\n",
       "  'police',\n",
       "  'industry',\n",
       "  'allowed',\n",
       "  '\"<mos',\n",
       "  'greater',\n",
       "  'era',\n",
       "  'view',\n",
       "  'philosophy',\n",
       "  'japan',\n",
       "  'business',\n",
       "  'beginning',\n",
       "  'possible',\n",
       "  'jews',\n",
       "  'brought',\n",
       "  'whose',\n",
       "  'organization',\n",
       "  'related',\n",
       "  'changes',\n",
       "  'particular',\n",
       "  'plants',\n",
       "  \"n't\",\n",
       "  'cases',\n",
       "  'outside',\n",
       "  'district',\n",
       "  'increase',\n",
       "  'caused',\n",
       "  'network',\n",
       "  'religion',\n",
       "  'policy',\n",
       "  '2005',\n",
       "  'final',\n",
       "  'wrote',\n",
       "  'architecture',\n",
       "  'aircraft',\n",
       "  'ireland',\n",
       "  'action',\n",
       "  'typically',\n",
       "  'county',\n",
       "  'album',\n",
       "  'space',\n",
       "  'position',\n",
       "  'includes',\n",
       "  'person',\n",
       "  'william',\n",
       "  'financial',\n",
       "  'required',\n",
       "  'remained',\n",
       "  'short',\n",
       "  'asia',\n",
       "  'laws',\n",
       "  'full',\n",
       "  'described',\n",
       "  '15',\n",
       "  'commercial',\n",
       "  'minister',\n",
       "  'saw',\n",
       "  'effect',\n",
       "  'seen',\n",
       "  'station',\n",
       "  'classical',\n",
       "  'designed',\n",
       "  'association',\n",
       "  'radio',\n",
       "  'right',\n",
       "  '2015',\n",
       "  'open',\n",
       "  'program',\n",
       "  'st.',\n",
       "  'design',\n",
       "  'member',\n",
       "  'referred',\n",
       "  'never',\n",
       "  'studies',\n",
       "  'started',\n",
       "  'status',\n",
       "  'australia',\n",
       "  'town',\n",
       "  'despite',\n",
       "  'scientific',\n",
       "  'little',\n",
       "  'special',\n",
       "  '25',\n",
       "  'eventually',\n",
       "  'together',\n",
       "  'buildings',\n",
       "  'leader',\n",
       "  'centuries',\n",
       "  'leading',\n",
       "  'universities',\n",
       "  'revolution',\n",
       "  'provided',\n",
       "  'uk',\n",
       "  'means',\n",
       "  '12',\n",
       "  'literature',\n",
       "  'mary',\n",
       "  'recent',\n",
       "  'greece',\n",
       "  'powers',\n",
       "  'territory',\n",
       "  'individual',\n",
       "  'limited',\n",
       "  'technology',\n",
       "  'widely',\n",
       "  'native',\n",
       "  'square',\n",
       "  'living',\n",
       "  'meaning',\n",
       "  'commonly',\n",
       "  'companies',\n",
       "  'legal',\n",
       "  'security',\n",
       "  'able',\n",
       "  'cause',\n",
       "  '4',\n",
       "  'evidence',\n",
       "  'americans',\n",
       "  'islamic',\n",
       "  '100',\n",
       "  'man',\n",
       "  'airport',\n",
       "  'supreme',\n",
       "  'primarily',\n",
       "  'whether',\n",
       "  'run',\n",
       "  'title',\n",
       "  'mass',\n",
       "  'source',\n",
       "  'larger',\n",
       "  'material',\n",
       "  'head',\n",
       "  'annual',\n",
       "  '30',\n",
       "  'words',\n",
       "  'nearly',\n",
       "  'regions',\n",
       "  'cup',\n",
       "  'originally',\n",
       "  'next',\n",
       "  'ottoman',\n",
       "  'grand',\n",
       "  'independence',\n",
       "  'italian',\n",
       "  'nature',\n",
       "  'seven',\n",
       "  'approximately',\n",
       "  'copper',\n",
       "  'f',\n",
       "  'division',\n",
       "  'specific',\n",
       "  'universal',\n",
       "  'software',\n",
       "  'imperial',\n",
       "  'mostly',\n",
       "  'plant',\n",
       "  'medical',\n",
       "  'start',\n",
       "  'dynasty',\n",
       "  'congress',\n",
       "  'close',\n",
       "  'beyoncé',\n",
       "  'cotton',\n",
       "  'dutch',\n",
       "  'nation',\n",
       "  'prior',\n",
       "  'computer',\n",
       "  'electric',\n",
       "  'working',\n",
       "  'scholars',\n",
       "  'taken',\n",
       "  'strong',\n",
       "  'construction',\n",
       "  'knowledge',\n",
       "  'canadian',\n",
       "  'father',\n",
       "  'economy',\n",
       "  'operations',\n",
       "  'chief',\n",
       "  'code',\n",
       "  'election',\n",
       "  'oil',\n",
       "  'paper',\n",
       "  'centre',\n",
       "  'italy',\n",
       "  'teams',\n",
       "  'mexico',\n",
       "  'largely',\n",
       "  'produce',\n",
       "  'adopted',\n",
       "  'administration',\n",
       "  'base',\n",
       "  'months',\n",
       "  'temperature',\n",
       "  'reached',\n",
       "  'release',\n",
       "  'help',\n",
       "  'yale',\n",
       "  'features',\n",
       "  'structure',\n",
       "  'apple',\n",
       "  'event',\n",
       "  'access',\n",
       "  'levels',\n",
       "  'site',\n",
       "  'lost',\n",
       "  'version',\n",
       "  'good',\n",
       "  'date',\n",
       "  'replaced',\n",
       "  'glass',\n",
       "  'charles',\n",
       "  'board',\n",
       "  'estimated',\n",
       "  'historical',\n",
       "  'sound',\n",
       "  'separate',\n",
       "  'subject',\n",
       "  'digital',\n",
       "  'reported',\n",
       "  'active',\n",
       "  'past',\n",
       "  'authority',\n",
       "  'kind',\n",
       "  'speed',\n",
       "  'elements',\n",
       "  'regional',\n",
       "  'gave',\n",
       "  '&',\n",
       "  'mother',\n",
       "  'opened',\n",
       "  'james',\n",
       "  'rome',\n",
       "  'longer',\n",
       "  'earth',\n",
       "  'km',\n",
       "  '2004',\n",
       "  'types',\n",
       "  'variety',\n",
       "  'elected',\n",
       "  'matter',\n",
       "  'museum',\n",
       "  'parliament',\n",
       "  'character',\n",
       "  'e.g.',\n",
       "  'ethnic',\n",
       "  'rise',\n",
       "  'return',\n",
       "  'orthodox',\n",
       "  'report',\n",
       "  'summer',\n",
       "  'born',\n",
       "  'palace',\n",
       "  'moved',\n",
       "  'churches',\n",
       "  'dell',\n",
       "  '11',\n",
       "  'direct',\n",
       "  'earlier',\n",
       "  'urban',\n",
       "  'animals',\n",
       "  'size',\n",
       "  'port',\n",
       "  'troops',\n",
       "  'son',\n",
       "  'concept',\n",
       "  'prime',\n",
       "  'saint',\n",
       "  'passed',\n",
       "  'cost',\n",
       "  'lines',\n",
       "  'smaller',\n",
       "  'blue',\n",
       "  'industrial',\n",
       "  'pope',\n",
       "  'uses',\n",
       "  'experience',\n",
       "  'involved',\n",
       "  'died',\n",
       "  'famous',\n",
       "  'lead',\n",
       "  'governor',\n",
       "  'future',\n",
       "  'internet',\n",
       "  '...',\n",
       "  'global',\n",
       "  'believed',\n",
       "  'physical',\n",
       "  'song',\n",
       "  'washington',\n",
       "  'served',\n",
       "  'fact',\n",
       "  'interest',\n",
       "  'province',\n",
       "  'influenced',\n",
       "  'needed]<mos',\n",
       "  'mi',\n",
       "  'sold',\n",
       "  'characters',\n",
       "  'hunting',\n",
       "  'therefore',\n",
       "  '18',\n",
       "  'come',\n",
       "  'create',\n",
       "  'went',\n",
       "  'personal',\n",
       "  'ten',\n",
       "  'hall',\n",
       "  'race',\n",
       "  'agreement',\n",
       "  'attack',\n",
       "  '6',\n",
       "  'store',\n",
       "  'defined',\n",
       "  '2000',\n",
       "  'minority',\n",
       "  'successful',\n",
       "  'zinc',\n",
       "  'complex',\n",
       "  'executive',\n",
       "  'climate',\n",
       "  'practice',\n",
       "  'birds',\n",
       "  'prince',\n",
       "  'remains',\n",
       "  'numerous',\n",
       "  'parties',\n",
       "  'young',\n",
       "  'earliest',\n",
       "  'away',\n",
       "  'sexual',\n",
       "  'campus',\n",
       "  'sent',\n",
       "  'arts',\n",
       "  'spread',\n",
       "  'response',\n",
       "  'directly',\n",
       "  'muslim',\n",
       "  'success',\n",
       "  'ad',\n",
       "  'egypt',\n",
       "  'value',\n",
       "  'added',\n",
       "  'ground',\n",
       "  'relatively',\n",
       "  'quality',\n",
       "  'anti',\n",
       "  'supported',\n",
       "  'stated',\n",
       "  'miami',\n",
       "  'previous',\n",
       "  'russia',\n",
       "  'might',\n",
       "  'tradition',\n",
       "  'amount',\n",
       "  'relationship',\n",
       "  'carolina',\n",
       "  'definition',\n",
       "  'mainly',\n",
       "  'child',\n",
       "  'hand',\n",
       "  'players',\n",
       "  'changed',\n",
       "  'artists',\n",
       "  'institutions',\n",
       "  'officially',\n",
       "  'coast',\n",
       "  'products',\n",
       "  'rest',\n",
       "  'pain',\n",
       "  'paul',\n",
       "  'wide',\n",
       "  'chopin',\n",
       "  'method',\n",
       "  'la',\n",
       "  '2003',\n",
       "  'forced',\n",
       "  'declared',\n",
       "  'mountains',\n",
       "  'highly',\n",
       "  'jesus',\n",
       "  'road',\n",
       "  'via',\n",
       "  'allow',\n",
       "  'communities',\n",
       "  'killed',\n",
       "  'compared',\n",
       "  'ever',\n",
       "  'israel',\n",
       "  '50',\n",
       "  '7',\n",
       "  'metal',\n",
       "  'solar',\n",
       "  'burke',\n",
       "  'always',\n",
       "  'initially',\n",
       "  'currently',\n",
       "  'training',\n",
       "  'henry',\n",
       "  '16',\n",
       "  'previously',\n",
       "  'fall',\n",
       "  'examples',\n",
       "  'humans',\n",
       "  'problems',\n",
       "  'divided',\n",
       "  'films',\n",
       "  'scale',\n",
       "  'entire',\n",
       "  'put',\n",
       "  'houston',\n",
       "  'memory',\n",
       "  'eight',\n",
       "  'launched',\n",
       "  'project',\n",
       "  'numbers',\n",
       "  'premier',\n",
       "  'towards',\n",
       "  'spain',\n",
       "  'issue',\n",
       "  'napoleon',\n",
       "  'hard',\n",
       "  'turn',\n",
       "  'devices',\n",
       "  'conflict',\n",
       "  'move',\n",
       "  'spoken',\n",
       "  'surface',\n",
       "  'feature',\n",
       "  '18th',\n",
       "  'ideas',\n",
       "  'activity',\n",
       "  'plan',\n",
       "  'cross',\n",
       "  'domestic',\n",
       "  'resulting',\n",
       "  'downtown',\n",
       "  'notable',\n",
       "  '14',\n",
       "  'exist',\n",
       "  'news',\n",
       "  'diego',\n",
       "  'sources',\n",
       "  'student',\n",
       "  'sports',\n",
       "  'writing',\n",
       "  'arab',\n",
       "  '£',\n",
       "  'occurred',\n",
       "  'resulted',\n",
       "  'census',\n",
       "  'soon',\n",
       "  'performance',\n",
       "  'worldwide',\n",
       "  'institute',\n",
       "  'recorded',\n",
       "  'speaking',\n",
       "  'defence',\n",
       "  'proposed',\n",
       "  'increasing',\n",
       "  'content',\n",
       "  'professional',\n",
       "  'already',\n",
       "  'hours',\n",
       "  'oldest',\n",
       "  '2001',\n",
       "  'foundation',\n",
       "  'atlantic',\n",
       "  'labour',\n",
       "  'pre',\n",
       "  'real',\n",
       "  'latter',\n",
       "  'better',\n",
       "  'band',\n",
       "  'heavy',\n",
       "  'contemporary',\n",
       "  'text',\n",
       "  'basic',\n",
       "  'sun',\n",
       "  'lived',\n",
       "  'remain',\n",
       "  'sense',\n",
       "  'mandolin',\n",
       "  'individuals',\n",
       "  'money',\n",
       "  'resistance',\n",
       "  'identity',\n",
       "  'applied',\n",
       "  'likely',\n",
       "  'ability',\n",
       "  'boston',\n",
       "  'dialects',\n",
       "  'ibn',\n",
       "  'ranked',\n",
       "  'robert',\n",
       "  'month',\n",
       "  'need',\n",
       "  'discovered',\n",
       "  'disease',\n",
       "  'units',\n",
       "  'yet',\n",
       "  'clubs',\n",
       "  'night',\n",
       "  'stations',\n",
       "  'irish',\n",
       "  'programs',\n",
       "  'begin',\n",
       "  'growing',\n",
       "  'medieval',\n",
       "  '40',\n",
       "  'fourth',\n",
       "  'peace',\n",
       "  'committee',\n",
       "  'ages',\n",
       "  'degree',\n",
       "  'loss',\n",
       "  'ocean',\n",
       "  '24',\n",
       "  'conditions',\n",
       "  'give',\n",
       "  'armenian',\n",
       "  'signed',\n",
       "  '’s',\n",
       "  'potential',\n",
       "  'management',\n",
       "  'nasser',\n",
       "  'true',\n",
       "  'co',\n",
       "  'presence',\n",
       "  'florida',\n",
       "  'operation',\n",
       "  'ft',\n",
       "  'competition',\n",
       "  'idea',\n",
       "  'argued',\n",
       "  'placed',\n",
       "  ...],\n",
       " 'unk_index': 0,\n",
       " 'stoi': defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f364ba44c40>>,\n",
       "             {'<unk>': 0,\n",
       "              '<pad>': 1,\n",
       "              '<sos>': 2,\n",
       "              '<eos>': 3,\n",
       "              ',': 4,\n",
       "              '.': 5,\n",
       "              '\"': 6,\n",
       "              '-': 7,\n",
       "              '(': 8,\n",
       "              ')': 9,\n",
       "              '>': 10,\n",
       "              '?': 11,\n",
       "              \"'s\": 12,\n",
       "              'is': 13,\n",
       "              'impossilbe': 14,\n",
       "              'also': 15,\n",
       "              'one': 16,\n",
       "              ';': 17,\n",
       "              'first': 18,\n",
       "              'new': 19,\n",
       "              'many': 20,\n",
       "              'city': 21,\n",
       "              'used': 22,\n",
       "              'two': 23,\n",
       "              '%': 24,\n",
       "              'time': 25,\n",
       "              'states': 26,\n",
       "              ':': 27,\n",
       "              'state': 28,\n",
       "              'world': 29,\n",
       "              \"'\": 30,\n",
       "              'may': 31,\n",
       "              'century': 32,\n",
       "              'united': 33,\n",
       "              'war': 34,\n",
       "              'year': 35,\n",
       "              'would': 36,\n",
       "              'the': 37,\n",
       "              'known': 38,\n",
       "              'people': 39,\n",
       "              'use': 40,\n",
       "              'years': 41,\n",
       "              'government': 42,\n",
       "              'system': 43,\n",
       "              'including': 44,\n",
       "              'however': 45,\n",
       "              'early': 46,\n",
       "              'called': 47,\n",
       "              'made': 48,\n",
       "              'part': 49,\n",
       "              'well': 50,\n",
       "              'since': 51,\n",
       "              'became': 52,\n",
       "              'number': 53,\n",
       "              'three': 54,\n",
       "              'high': 55,\n",
       "              'later': 56,\n",
       "              'north': 57,\n",
       "              'american': 58,\n",
       "              'often': 59,\n",
       "              'national': 60,\n",
       "              'university': 61,\n",
       "              'million': 62,\n",
       "              'power': 63,\n",
       "              'population': 64,\n",
       "              'south': 65,\n",
       "              'major': 66,\n",
       "              'music': 67,\n",
       "              'area': 68,\n",
       "              'based': 69,\n",
       "              'british': 70,\n",
       "              ']': 71,\n",
       "              'several': 72,\n",
       "              'language': 73,\n",
       "              'period': 74,\n",
       "              'large': 75,\n",
       "              '–': 76,\n",
       "              'law': 77,\n",
       "              'second': 78,\n",
       "              'school': 79,\n",
       "              'west': 80,\n",
       "              'name': 81,\n",
       "              'although': 82,\n",
       "              'group': 83,\n",
       "              'much': 84,\n",
       "              'public': 85,\n",
       "              'of': 86,\n",
       "              'country': 87,\n",
       "              'form': 88,\n",
       "              'largest': 89,\n",
       "              'church': 90,\n",
       "              'french': 91,\n",
       "              'include': 92,\n",
       "              'within': 93,\n",
       "              'like': 94,\n",
       "              'modern': 95,\n",
       "              'around': 96,\n",
       "              'led': 97,\n",
       "              'could': 98,\n",
       "              'great': 99,\n",
       "              'political': 100,\n",
       "              'and': 101,\n",
       "              'found': 102,\n",
       "              'general': 103,\n",
       "              'east': 104,\n",
       "              'began': 105,\n",
       "              'international': 106,\n",
       "              'among': 107,\n",
       "              'u.s.': 108,\n",
       "              '—': 109,\n",
       "              '/': 110,\n",
       "              'day': 111,\n",
       "              'english': 112,\n",
       "              'european': 113,\n",
       "              'according': 114,\n",
       "              'john': 115,\n",
       "              'end': 116,\n",
       "              'different': 117,\n",
       "              'work': 118,\n",
       "              'example': 119,\n",
       "              'empire': 120,\n",
       "              'term': 121,\n",
       "              'german': 122,\n",
       "              'company': 123,\n",
       "              'long': 124,\n",
       "              'common': 125,\n",
       "              'non': 126,\n",
       "              'four': 127,\n",
       "              'another': 128,\n",
       "              'due': 129,\n",
       "              'party': 130,\n",
       "              'even': 131,\n",
       "              'house': 132,\n",
       "              'development': 133,\n",
       "              'countries': 134,\n",
       "              'military': 135,\n",
       "              'greek': 136,\n",
       "              'still': 137,\n",
       "              '$': 138,\n",
       "              'following': 139,\n",
       "              'along': 140,\n",
       "              'president': 141,\n",
       "              'late': 142,\n",
       "              'considered': 143,\n",
       "              'established': 144,\n",
       "              'europe': 145,\n",
       "              'control': 146,\n",
       "              'league': 147,\n",
       "              'human': 148,\n",
       "              'energy': 149,\n",
       "              'roman': 150,\n",
       "              'central': 151,\n",
       "              'western': 152,\n",
       "              'life': 153,\n",
       "              'chinese': 154,\n",
       "              'important': 155,\n",
       "              'court': 156,\n",
       "              'groups': 157,\n",
       "              'region': 158,\n",
       "              'developed': 159,\n",
       "              'species': 160,\n",
       "              'areas': 161,\n",
       "              'federal': 162,\n",
       "              'become': 163,\n",
       "              'army': 164,\n",
       "              'de': 165,\n",
       "              'order': 166,\n",
       "              'small': 167,\n",
       "              'members': 168,\n",
       "              'air': 169,\n",
       "              'home': 170,\n",
       "              '°': 171,\n",
       "              'social': 172,\n",
       "              'china': 173,\n",
       "              'france': 174,\n",
       "              'history': 175,\n",
       "              'place': 176,\n",
       "              'local': 177,\n",
       "              'union': 178,\n",
       "              'film': 179,\n",
       "              'island': 180,\n",
       "              'forces': 181,\n",
       "              'water': 182,\n",
       "              'five': 183,\n",
       "              'old': 184,\n",
       "              'support': 185,\n",
       "              'usually': 186,\n",
       "              'using': 187,\n",
       "              '1': 188,\n",
       "              'god': 189,\n",
       "              'king': 190,\n",
       "              'times': 191,\n",
       "              'service': 192,\n",
       "              'light': 193,\n",
       "              'though': 194,\n",
       "              'us': 195,\n",
       "              'various': 196,\n",
       "              'without': 197,\n",
       "              'death': 198,\n",
       "              'located': 199,\n",
       "              'held': 200,\n",
       "              'per': 201,\n",
       "              'set': 202,\n",
       "              'religious': 203,\n",
       "              'season': 204,\n",
       "              'act': 205,\n",
       "              'less': 206,\n",
       "              'eastern': 207,\n",
       "              'york': 208,\n",
       "              'london': 209,\n",
       "              'third': 210,\n",
       "              'type': 211,\n",
       "              'india': 212,\n",
       "              'college': 213,\n",
       "              'process': 214,\n",
       "              'middle': 215,\n",
       "              'england': 216,\n",
       "              'land': 217,\n",
       "              'white': 218,\n",
       "              'main': 219,\n",
       "              'northern': 220,\n",
       "              'soviet': 221,\n",
       "              'last': 222,\n",
       "              'research': 223,\n",
       "              'schools': 224,\n",
       "              'education': 225,\n",
       "              'make': 226,\n",
       "              'back': 227,\n",
       "              'kingdom': 228,\n",
       "              'included': 229,\n",
       "              'royal': 230,\n",
       "              'standard': 231,\n",
       "              'center': 232,\n",
       "              'family': 233,\n",
       "              'built': 234,\n",
       "              'needed': 235,\n",
       "              'southern': 236,\n",
       "              'force': 237,\n",
       "              'study': 238,\n",
       "              'game': 239,\n",
       "              'way': 240,\n",
       "              'single': 241,\n",
       "              'released': 242,\n",
       "              'germany': 243,\n",
       "              'culture': 244,\n",
       "              'popular': 245,\n",
       "              'britain': 246,\n",
       "              'free': 247,\n",
       "              'systems': 248,\n",
       "              'black': 249,\n",
       "              'languages': 250,\n",
       "              'age': 251,\n",
       "              'similar': 252,\n",
       "              'building': 253,\n",
       "              'september': 254,\n",
       "              'generally': 255,\n",
       "              '2010': 256,\n",
       "              'took': 257,\n",
       "              'america': 258,\n",
       "              'low': 259,\n",
       "              'result': 260,\n",
       "              'original': 261,\n",
       "              'top': 262,\n",
       "              'red': 263,\n",
       "              'students': 264,\n",
       "              'created': 265,\n",
       "              'former': 266,\n",
       "              'produced': 267,\n",
       "              'economic': 268,\n",
       "              'river': 269,\n",
       "              'others': 270,\n",
       "              'council': 271,\n",
       "              'march': 272,\n",
       "              'near': 273,\n",
       "              'higher': 274,\n",
       "              'republic': 275,\n",
       "              'current': 276,\n",
       "              'came': 277,\n",
       "              '2': 278,\n",
       "              'ii': 279,\n",
       "              'best': 280,\n",
       "              'line': 281,\n",
       "              'said': 282,\n",
       "              'especially': 283,\n",
       "              'art': 284,\n",
       "              'production': 285,\n",
       "              'june': 286,\n",
       "              'throughout': 287,\n",
       "              '10': 288,\n",
       "              '2009': 289,\n",
       "              'continued': 290,\n",
       "              'level': 291,\n",
       "              'total': 292,\n",
       "              '3': 293,\n",
       "              'capital': 294,\n",
       "              'body': 295,\n",
       "              'significant': 296,\n",
       "              'given': 297,\n",
       "              '2008': 298,\n",
       "              'january': 299,\n",
       "              'rule': 300,\n",
       "              'football': 301,\n",
       "              'team': 302,\n",
       "              'sea': 303,\n",
       "              'rights': 304,\n",
       "              'thus': 305,\n",
       "              'bc': 306,\n",
       "              'sometimes': 307,\n",
       "              'rather': 308,\n",
       "              'today': 309,\n",
       "              'average': 310,\n",
       "              'every': 311,\n",
       "              'formed': 312,\n",
       "              'official': 313,\n",
       "              'children': 314,\n",
       "              'african': 315,\n",
       "              'july': 316,\n",
       "              'al': 317,\n",
       "              'parts': 318,\n",
       "              'queen': 319,\n",
       "              'october': 320,\n",
       "              'take': 321,\n",
       "              '2011': 322,\n",
       "              'science': 323,\n",
       "              '2013': 324,\n",
       "              'book': 325,\n",
       "              'data': 326,\n",
       "              'must': 327,\n",
       "              'russian': 328,\n",
       "              'natural': 329,\n",
       "              'style': 330,\n",
       "              'majority': 331,\n",
       "              'cities': 332,\n",
       "              'women': 333,\n",
       "              'series': 334,\n",
       "              'december': 335,\n",
       "              'influence': 336,\n",
       "              '19th': 337,\n",
       "              ' ': 338,\n",
       "              '2007': 339,\n",
       "              'theory': 340,\n",
       "              'addition': 341,\n",
       "              'either': 342,\n",
       "              'cultural': 343,\n",
       "              'available': 344,\n",
       "              'case': 345,\n",
       "              'see': 346,\n",
       "              '2012': 347,\n",
       "              'battle': 348,\n",
       "              'word': 349,\n",
       "              'field': 350,\n",
       "              'highest': 351,\n",
       "              'point': 352,\n",
       "              'traditional': 353,\n",
       "              'men': 354,\n",
       "              'trade': 355,\n",
       "              'range': 356,\n",
       "              'particularly': 357,\n",
       "              'present': 358,\n",
       "              'spanish': 359,\n",
       "              'november': 360,\n",
       "              'days': 361,\n",
       "              '20': 362,\n",
       "              'named': 363,\n",
       "              'founded': 364,\n",
       "              'half': 365,\n",
       "              'written': 366,\n",
       "              'ancient': 367,\n",
       "              'increased': 368,\n",
       "              'forms': 369,\n",
       "              'percent': 370,\n",
       "              'left': 371,\n",
       "              'role': 372,\n",
       "              'office': 373,\n",
       "              'show': 374,\n",
       "              'games': 375,\n",
       "              'across': 376,\n",
       "              'published': 377,\n",
       "              'a': 378,\n",
       "              'rock': 379,\n",
       "              'civil': 380,\n",
       "              'billion': 381,\n",
       "              'works': 382,\n",
       "              'record': 383,\n",
       "              'private': 384,\n",
       "              'society': 385,\n",
       "              '2014': 386,\n",
       "              'making': 387,\n",
       "              'played': 388,\n",
       "              'to': 389,\n",
       "              'club': 390,\n",
       "              'class': 391,\n",
       "              'change': 392,\n",
       "              'terms': 393,\n",
       "              'market': 394,\n",
       "              'live': 395,\n",
       "              'services': 396,\n",
       "              'introduced': 397,\n",
       "              'received': 398,\n",
       "              'april': 399,\n",
       "              '2006': 400,\n",
       "              'africa': 401,\n",
       "              'community': 402,\n",
       "              'information': 403,\n",
       "              'lower': 404,\n",
       "              'august': 405,\n",
       "              'japanese': 406,\n",
       "              'park': 407,\n",
       "              'upon': 408,\n",
       "              'latin': 409,\n",
       "              'victoria': 410,\n",
       "              'video': 411,\n",
       "              'foreign': 412,\n",
       "              'movement': 413,\n",
       "              'c': 414,\n",
       "              'islands': 415,\n",
       "              'george': 416,\n",
       "              'associated': 417,\n",
       "              'provide': 418,\n",
       "              'rate': 419,\n",
       "              'announced': 420,\n",
       "              'street': 421,\n",
       "              'paris': 422,\n",
       "              'department': 423,\n",
       "              'constitution': 424,\n",
       "              'san': 425,\n",
       "              'green': 426,\n",
       "              'growth': 427,\n",
       "              'christian': 428,\n",
       "              'independent': 429,\n",
       "              'television': 430,\n",
       "              'nations': 431,\n",
       "              'events': 432,\n",
       "              'least': 433,\n",
       "              'records': 434,\n",
       "              'primary': 435,\n",
       "              'far': 436,\n",
       "              'certain': 437,\n",
       "              'thought': 438,\n",
       "              'jewish': 439,\n",
       "              'instead': 440,\n",
       "              '20th': 441,\n",
       "              '5': 442,\n",
       "              'february': 443,\n",
       "              'media': 444,\n",
       "              'self': 445,\n",
       "              'catholic': 446,\n",
       "              'six': 447,\n",
       "              'windows': 448,\n",
       "              'model': 449,\n",
       "              'treaty': 450,\n",
       "              '8': 451,\n",
       "              'indian': 452,\n",
       "              'in': 453,\n",
       "              'food': 454,\n",
       "              'health': 455,\n",
       "              'followed': 456,\n",
       "              'almost': 457,\n",
       "              'emperor': 458,\n",
       "              '[': 459,\n",
       "              'play': 460,\n",
       "              'side': 461,\n",
       "              'post': 462,\n",
       "              'color': 463,\n",
       "              'canada': 464,\n",
       "              'police': 465,\n",
       "              'industry': 466,\n",
       "              'allowed': 467,\n",
       "              '\"<mos': 468,\n",
       "              'greater': 469,\n",
       "              'era': 470,\n",
       "              'view': 471,\n",
       "              'philosophy': 472,\n",
       "              'japan': 473,\n",
       "              'business': 474,\n",
       "              'beginning': 475,\n",
       "              'possible': 476,\n",
       "              'jews': 477,\n",
       "              'brought': 478,\n",
       "              'whose': 479,\n",
       "              'organization': 480,\n",
       "              'related': 481,\n",
       "              'changes': 482,\n",
       "              'particular': 483,\n",
       "              'plants': 484,\n",
       "              \"n't\": 485,\n",
       "              'cases': 486,\n",
       "              'outside': 487,\n",
       "              'district': 488,\n",
       "              'increase': 489,\n",
       "              'caused': 490,\n",
       "              'network': 491,\n",
       "              'religion': 492,\n",
       "              'policy': 493,\n",
       "              '2005': 494,\n",
       "              'final': 495,\n",
       "              'wrote': 496,\n",
       "              'architecture': 497,\n",
       "              'aircraft': 498,\n",
       "              'ireland': 499,\n",
       "              'action': 500,\n",
       "              'typically': 501,\n",
       "              'county': 502,\n",
       "              'album': 503,\n",
       "              'space': 504,\n",
       "              'position': 505,\n",
       "              'includes': 506,\n",
       "              'person': 507,\n",
       "              'william': 508,\n",
       "              'financial': 509,\n",
       "              'required': 510,\n",
       "              'remained': 511,\n",
       "              'short': 512,\n",
       "              'asia': 513,\n",
       "              'laws': 514,\n",
       "              'full': 515,\n",
       "              'described': 516,\n",
       "              '15': 517,\n",
       "              'commercial': 518,\n",
       "              'minister': 519,\n",
       "              'saw': 520,\n",
       "              'effect': 521,\n",
       "              'seen': 522,\n",
       "              'station': 523,\n",
       "              'classical': 524,\n",
       "              'designed': 525,\n",
       "              'association': 526,\n",
       "              'radio': 527,\n",
       "              'right': 528,\n",
       "              '2015': 529,\n",
       "              'open': 530,\n",
       "              'program': 531,\n",
       "              'st.': 532,\n",
       "              'design': 533,\n",
       "              'member': 534,\n",
       "              'referred': 535,\n",
       "              'never': 536,\n",
       "              'studies': 537,\n",
       "              'started': 538,\n",
       "              'status': 539,\n",
       "              'australia': 540,\n",
       "              'town': 541,\n",
       "              'despite': 542,\n",
       "              'scientific': 543,\n",
       "              'little': 544,\n",
       "              'special': 545,\n",
       "              '25': 546,\n",
       "              'eventually': 547,\n",
       "              'together': 548,\n",
       "              'buildings': 549,\n",
       "              'leader': 550,\n",
       "              'centuries': 551,\n",
       "              'leading': 552,\n",
       "              'universities': 553,\n",
       "              'revolution': 554,\n",
       "              'provided': 555,\n",
       "              'uk': 556,\n",
       "              'means': 557,\n",
       "              '12': 558,\n",
       "              'literature': 559,\n",
       "              'mary': 560,\n",
       "              'recent': 561,\n",
       "              'greece': 562,\n",
       "              'powers': 563,\n",
       "              'territory': 564,\n",
       "              'individual': 565,\n",
       "              'limited': 566,\n",
       "              'technology': 567,\n",
       "              'widely': 568,\n",
       "              'native': 569,\n",
       "              'square': 570,\n",
       "              'living': 571,\n",
       "              'meaning': 572,\n",
       "              'commonly': 573,\n",
       "              'companies': 574,\n",
       "              'legal': 575,\n",
       "              'security': 576,\n",
       "              'able': 577,\n",
       "              'cause': 578,\n",
       "              '4': 579,\n",
       "              'evidence': 580,\n",
       "              'americans': 581,\n",
       "              'islamic': 582,\n",
       "              '100': 583,\n",
       "              'man': 584,\n",
       "              'airport': 585,\n",
       "              'supreme': 586,\n",
       "              'primarily': 587,\n",
       "              'whether': 588,\n",
       "              'run': 589,\n",
       "              'title': 590,\n",
       "              'mass': 591,\n",
       "              'source': 592,\n",
       "              'larger': 593,\n",
       "              'material': 594,\n",
       "              'head': 595,\n",
       "              'annual': 596,\n",
       "              '30': 597,\n",
       "              'words': 598,\n",
       "              'nearly': 599,\n",
       "              'regions': 600,\n",
       "              'cup': 601,\n",
       "              'originally': 602,\n",
       "              'next': 603,\n",
       "              'ottoman': 604,\n",
       "              'grand': 605,\n",
       "              'independence': 606,\n",
       "              'italian': 607,\n",
       "              'nature': 608,\n",
       "              'seven': 609,\n",
       "              'approximately': 610,\n",
       "              'copper': 611,\n",
       "              'f': 612,\n",
       "              'division': 613,\n",
       "              'specific': 614,\n",
       "              'universal': 615,\n",
       "              'software': 616,\n",
       "              'imperial': 617,\n",
       "              'mostly': 618,\n",
       "              'plant': 619,\n",
       "              'medical': 620,\n",
       "              'start': 621,\n",
       "              'dynasty': 622,\n",
       "              'congress': 623,\n",
       "              'close': 624,\n",
       "              'beyoncé': 625,\n",
       "              'cotton': 626,\n",
       "              'dutch': 627,\n",
       "              'nation': 628,\n",
       "              'prior': 629,\n",
       "              'computer': 630,\n",
       "              'electric': 631,\n",
       "              'working': 632,\n",
       "              'scholars': 633,\n",
       "              'taken': 634,\n",
       "              'strong': 635,\n",
       "              'construction': 636,\n",
       "              'knowledge': 637,\n",
       "              'canadian': 638,\n",
       "              'father': 639,\n",
       "              'economy': 640,\n",
       "              'operations': 641,\n",
       "              'chief': 642,\n",
       "              'code': 643,\n",
       "              'election': 644,\n",
       "              'oil': 645,\n",
       "              'paper': 646,\n",
       "              'centre': 647,\n",
       "              'italy': 648,\n",
       "              'teams': 649,\n",
       "              'mexico': 650,\n",
       "              'largely': 651,\n",
       "              'produce': 652,\n",
       "              'adopted': 653,\n",
       "              'administration': 654,\n",
       "              'base': 655,\n",
       "              'months': 656,\n",
       "              'temperature': 657,\n",
       "              'reached': 658,\n",
       "              'release': 659,\n",
       "              'help': 660,\n",
       "              'yale': 661,\n",
       "              'features': 662,\n",
       "              'structure': 663,\n",
       "              'apple': 664,\n",
       "              'event': 665,\n",
       "              'access': 666,\n",
       "              'levels': 667,\n",
       "              'site': 668,\n",
       "              'lost': 669,\n",
       "              'version': 670,\n",
       "              'good': 671,\n",
       "              'date': 672,\n",
       "              'replaced': 673,\n",
       "              'glass': 674,\n",
       "              'charles': 675,\n",
       "              'board': 676,\n",
       "              'estimated': 677,\n",
       "              'historical': 678,\n",
       "              'sound': 679,\n",
       "              'separate': 680,\n",
       "              'subject': 681,\n",
       "              'digital': 682,\n",
       "              'reported': 683,\n",
       "              'active': 684,\n",
       "              'past': 685,\n",
       "              'authority': 686,\n",
       "              'kind': 687,\n",
       "              'speed': 688,\n",
       "              'elements': 689,\n",
       "              'regional': 690,\n",
       "              'gave': 691,\n",
       "              '&': 692,\n",
       "              'mother': 693,\n",
       "              'opened': 694,\n",
       "              'james': 695,\n",
       "              'rome': 696,\n",
       "              'longer': 697,\n",
       "              'earth': 698,\n",
       "              'km': 699,\n",
       "              '2004': 700,\n",
       "              'types': 701,\n",
       "              'variety': 702,\n",
       "              'elected': 703,\n",
       "              'matter': 704,\n",
       "              'museum': 705,\n",
       "              'parliament': 706,\n",
       "              'character': 707,\n",
       "              'e.g.': 708,\n",
       "              'ethnic': 709,\n",
       "              'rise': 710,\n",
       "              'return': 711,\n",
       "              'orthodox': 712,\n",
       "              'report': 713,\n",
       "              'summer': 714,\n",
       "              'born': 715,\n",
       "              'palace': 716,\n",
       "              'moved': 717,\n",
       "              'churches': 718,\n",
       "              'dell': 719,\n",
       "              '11': 720,\n",
       "              'direct': 721,\n",
       "              'earlier': 722,\n",
       "              'urban': 723,\n",
       "              'animals': 724,\n",
       "              'size': 725,\n",
       "              'port': 726,\n",
       "              'troops': 727,\n",
       "              'son': 728,\n",
       "              'concept': 729,\n",
       "              'prime': 730,\n",
       "              'saint': 731,\n",
       "              'passed': 732,\n",
       "              'cost': 733,\n",
       "              'lines': 734,\n",
       "              'smaller': 735,\n",
       "              'blue': 736,\n",
       "              'industrial': 737,\n",
       "              'pope': 738,\n",
       "              'uses': 739,\n",
       "              'experience': 740,\n",
       "              'involved': 741,\n",
       "              'died': 742,\n",
       "              'famous': 743,\n",
       "              'lead': 744,\n",
       "              'governor': 745,\n",
       "              'future': 746,\n",
       "              'internet': 747,\n",
       "              '...': 748,\n",
       "              'global': 749,\n",
       "              'believed': 750,\n",
       "              'physical': 751,\n",
       "              'song': 752,\n",
       "              'washington': 753,\n",
       "              'served': 754,\n",
       "              'fact': 755,\n",
       "              'interest': 756,\n",
       "              'province': 757,\n",
       "              'influenced': 758,\n",
       "              'needed]<mos': 759,\n",
       "              'mi': 760,\n",
       "              'sold': 761,\n",
       "              'characters': 762,\n",
       "              'hunting': 763,\n",
       "              'therefore': 764,\n",
       "              '18': 765,\n",
       "              'come': 766,\n",
       "              'create': 767,\n",
       "              'went': 768,\n",
       "              'personal': 769,\n",
       "              'ten': 770,\n",
       "              'hall': 771,\n",
       "              'race': 772,\n",
       "              'agreement': 773,\n",
       "              'attack': 774,\n",
       "              '6': 775,\n",
       "              'store': 776,\n",
       "              'defined': 777,\n",
       "              '2000': 778,\n",
       "              'minority': 779,\n",
       "              'successful': 780,\n",
       "              'zinc': 781,\n",
       "              'complex': 782,\n",
       "              'executive': 783,\n",
       "              'climate': 784,\n",
       "              'practice': 785,\n",
       "              'birds': 786,\n",
       "              'prince': 787,\n",
       "              'remains': 788,\n",
       "              'numerous': 789,\n",
       "              'parties': 790,\n",
       "              'young': 791,\n",
       "              'earliest': 792,\n",
       "              'away': 793,\n",
       "              'sexual': 794,\n",
       "              'campus': 795,\n",
       "              'sent': 796,\n",
       "              'arts': 797,\n",
       "              'spread': 798,\n",
       "              'response': 799,\n",
       "              'directly': 800,\n",
       "              'muslim': 801,\n",
       "              'success': 802,\n",
       "              'ad': 803,\n",
       "              'egypt': 804,\n",
       "              'value': 805,\n",
       "              'added': 806,\n",
       "              'ground': 807,\n",
       "              'relatively': 808,\n",
       "              'quality': 809,\n",
       "              'anti': 810,\n",
       "              'supported': 811,\n",
       "              'stated': 812,\n",
       "              'miami': 813,\n",
       "              'previous': 814,\n",
       "              'russia': 815,\n",
       "              'might': 816,\n",
       "              'tradition': 817,\n",
       "              'amount': 818,\n",
       "              'relationship': 819,\n",
       "              'carolina': 820,\n",
       "              'definition': 821,\n",
       "              'mainly': 822,\n",
       "              'child': 823,\n",
       "              'hand': 824,\n",
       "              'players': 825,\n",
       "              'changed': 826,\n",
       "              'artists': 827,\n",
       "              'institutions': 828,\n",
       "              'officially': 829,\n",
       "              'coast': 830,\n",
       "              'products': 831,\n",
       "              'rest': 832,\n",
       "              'pain': 833,\n",
       "              'paul': 834,\n",
       "              'wide': 835,\n",
       "              'chopin': 836,\n",
       "              'method': 837,\n",
       "              'la': 838,\n",
       "              '2003': 839,\n",
       "              'forced': 840,\n",
       "              'declared': 841,\n",
       "              'mountains': 842,\n",
       "              'highly': 843,\n",
       "              'jesus': 844,\n",
       "              'road': 845,\n",
       "              'via': 846,\n",
       "              'allow': 847,\n",
       "              'communities': 848,\n",
       "              'killed': 849,\n",
       "              'compared': 850,\n",
       "              'ever': 851,\n",
       "              'israel': 852,\n",
       "              '50': 853,\n",
       "              '7': 854,\n",
       "              'metal': 855,\n",
       "              'solar': 856,\n",
       "              'burke': 857,\n",
       "              'always': 858,\n",
       "              'initially': 859,\n",
       "              'currently': 860,\n",
       "              'training': 861,\n",
       "              'henry': 862,\n",
       "              '16': 863,\n",
       "              'previously': 864,\n",
       "              'fall': 865,\n",
       "              'examples': 866,\n",
       "              'humans': 867,\n",
       "              'problems': 868,\n",
       "              'divided': 869,\n",
       "              'films': 870,\n",
       "              'scale': 871,\n",
       "              'entire': 872,\n",
       "              'put': 873,\n",
       "              'houston': 874,\n",
       "              'memory': 875,\n",
       "              'eight': 876,\n",
       "              'launched': 877,\n",
       "              'project': 878,\n",
       "              'numbers': 879,\n",
       "              'premier': 880,\n",
       "              'towards': 881,\n",
       "              'spain': 882,\n",
       "              'issue': 883,\n",
       "              'napoleon': 884,\n",
       "              'hard': 885,\n",
       "              'turn': 886,\n",
       "              'devices': 887,\n",
       "              'conflict': 888,\n",
       "              'move': 889,\n",
       "              'spoken': 890,\n",
       "              'surface': 891,\n",
       "              'feature': 892,\n",
       "              '18th': 893,\n",
       "              'ideas': 894,\n",
       "              'activity': 895,\n",
       "              'plan': 896,\n",
       "              'cross': 897,\n",
       "              'domestic': 898,\n",
       "              'resulting': 899,\n",
       "              'downtown': 900,\n",
       "              'notable': 901,\n",
       "              '14': 902,\n",
       "              'exist': 903,\n",
       "              'news': 904,\n",
       "              'diego': 905,\n",
       "              'sources': 906,\n",
       "              'student': 907,\n",
       "              'sports': 908,\n",
       "              'writing': 909,\n",
       "              'arab': 910,\n",
       "              '£': 911,\n",
       "              'occurred': 912,\n",
       "              'resulted': 913,\n",
       "              'census': 914,\n",
       "              'soon': 915,\n",
       "              'performance': 916,\n",
       "              'worldwide': 917,\n",
       "              'institute': 918,\n",
       "              'recorded': 919,\n",
       "              'speaking': 920,\n",
       "              'defence': 921,\n",
       "              'proposed': 922,\n",
       "              'increasing': 923,\n",
       "              'content': 924,\n",
       "              'professional': 925,\n",
       "              'already': 926,\n",
       "              'hours': 927,\n",
       "              'oldest': 928,\n",
       "              '2001': 929,\n",
       "              'foundation': 930,\n",
       "              'atlantic': 931,\n",
       "              'labour': 932,\n",
       "              'pre': 933,\n",
       "              'real': 934,\n",
       "              'latter': 935,\n",
       "              'better': 936,\n",
       "              'band': 937,\n",
       "              'heavy': 938,\n",
       "              'contemporary': 939,\n",
       "              'text': 940,\n",
       "              'basic': 941,\n",
       "              'sun': 942,\n",
       "              'lived': 943,\n",
       "              'remain': 944,\n",
       "              'sense': 945,\n",
       "              'mandolin': 946,\n",
       "              'individuals': 947,\n",
       "              'money': 948,\n",
       "              'resistance': 949,\n",
       "              'identity': 950,\n",
       "              'applied': 951,\n",
       "              'likely': 952,\n",
       "              'ability': 953,\n",
       "              'boston': 954,\n",
       "              'dialects': 955,\n",
       "              'ibn': 956,\n",
       "              'ranked': 957,\n",
       "              'robert': 958,\n",
       "              'month': 959,\n",
       "              'need': 960,\n",
       "              'discovered': 961,\n",
       "              'disease': 962,\n",
       "              'units': 963,\n",
       "              'yet': 964,\n",
       "              'clubs': 965,\n",
       "              'night': 966,\n",
       "              'stations': 967,\n",
       "              'irish': 968,\n",
       "              'programs': 969,\n",
       "              'begin': 970,\n",
       "              'growing': 971,\n",
       "              'medieval': 972,\n",
       "              '40': 973,\n",
       "              'fourth': 974,\n",
       "              'peace': 975,\n",
       "              'committee': 976,\n",
       "              'ages': 977,\n",
       "              'degree': 978,\n",
       "              'loss': 979,\n",
       "              'ocean': 980,\n",
       "              '24': 981,\n",
       "              'conditions': 982,\n",
       "              'give': 983,\n",
       "              'armenian': 984,\n",
       "              'signed': 985,\n",
       "              '’s': 986,\n",
       "              'potential': 987,\n",
       "              'management': 988,\n",
       "              'nasser': 989,\n",
       "              'true': 990,\n",
       "              'co': 991,\n",
       "              'presence': 992,\n",
       "              'florida': 993,\n",
       "              'operation': 994,\n",
       "              'ft': 995,\n",
       "              'competition': 996,\n",
       "              'idea': 997,\n",
       "              'argued': 998,\n",
       "              'placed': 999,\n",
       "              ...}),\n",
       " 'vectors': tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
       "         [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n",
       "         [-0.1020,  1.6282,  2.1635,  ..., -0.6009, -0.1467,  0.0285],\n",
       "         ...,\n",
       "         [ 0.2491,  0.0723, -0.0139,  ..., -0.2833, -0.2802, -0.1625],\n",
       "         [-0.7731, -2.8761, -0.8439,  ..., -0.3820,  0.7937,  0.0901],\n",
       "         [ 1.6736, -1.4406, -1.5543,  ..., -1.2282,  1.4249, -0.1703]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(Question.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the vocabulary for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:48.758174Z",
     "start_time": "2021-01-26T16:45:48.493255Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "with open('question_tokenizer.pkl', 'wb') as tokens: \n",
    "    pickle.dump(Question.vocab.stoi, tokens)\n",
    "# with open(\"answer_tokenizer.pkl\", \"wb\") as tokens:\n",
    "#     pickle.dump(Answer.vocab.stoi, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Seq2Seq Model\n",
    "\n",
    "### Encoder\n",
    "\n",
    "The encoder is similar to the previous one, with the multi-layer LSTM swapped for a single-layer GRU. We also don't pass the dropout as an argument to the GRU as that dropout is used between each layer of a multi-layered RNN. As we only have a single layer, PyTorch will display a warning if we try and use pass a dropout value to it.\n",
    "\n",
    "Another thing to note about the GRU is that it only requires and returns a hidden state, there is no cell state like in the LSTM.\n",
    "\n",
    "$$\\begin{align*}\n",
    "h_t &= \\text{GRU}(e(x_t), h_{t-1})\\\\\n",
    "(h_t, c_t) &= \\text{LSTM}(e(x_t), h_{t-1}, c_{t-1})\\\\\n",
    "h_t &= \\text{RNN}(e(x_t), h_{t-1})\n",
    "\\end{align*}$$\n",
    "\n",
    "From the equations above, it looks like the RNN and the GRU are identical. Inside the GRU, however, is a number of *gating mechanisms* that control the information flow in to and out of the hidden state (similar to an LSTM). Again, for more info, check out [this](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) excellent post. \n",
    "\n",
    "The rest of the encoder should be very familar from the last session, it takes in a sequence, $X = \\{x_1, x_2, ... , x_T\\}$, passes it through the embedding layer, recurrently calculates hidden states, $H = \\{h_1, h_2, ..., h_T\\}$, and returns a context vector (the final hidden state), $z=h_T$.\n",
    "\n",
    "$$h_t = \\text{EncoderGRU}(e(x_t), h_{t-1})$$\n",
    "\n",
    "This is identical to the encoder of the general seq2seq model, with all the \"magic\" happening inside the GRU (green).\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq5.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:52.206923Z",
     "start_time": "2021-01-26T16:45:52.203400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    encoder rakes ainpuyt and runs it through the lstm\n",
    "    for example let's say the input size is [30,128],\n",
    "    here 30 means 30 words/onehot and 128 means batch size\n",
    "    \n",
    "    first pass it through the embedding dim of let's say 512\n",
    "    so the embedding output will bw [30,128,512]\n",
    "    then pass this to lstm which will give you output and hidden cell state\n",
    "    outputs wil have output at each time step so the first dim is sec_len\n",
    "    hidden and cell is the final state output so they don't have src_len in the output \n",
    "    let's say hidden dim for lstm is 10\n",
    "    outputs = [src_len,batch_size,hid_dim*n_layers]\n",
    "    hidden = [n layers * n directions, batch size, hid dim] [2,128,10] 2 for 2 layer\n",
    "    cell = [n layers * n directions, batch size, hid dim] [2,128,10] 2 for 2 layer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim) #no dropout as only one layer!\n",
    "        self.rnn = nn.GRU(emb_dim,hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src = [src_len, batch_size, emb_dim]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # embedded = [src_len, batch_size, emb_dim]\n",
    "        outputs, hidden = self.rnn(embedded)  #no cell state because we are using GRU\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        # outputs are always from top hidden layer\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "The decoder is where the implementation differs significantly from the previous model and we alleviate some of the information compression.\n",
    "\n",
    "Instead of the GRU in the decoder taking just the embedded target token, $d(y_t)$ and the previous hidden state $s_{t-1}$ as inputs, it also takes the context vector $z$. \n",
    "\n",
    "$$s_t = \\text{DecoderGRU}(d(y_t), s_{t-1}, z)$$\n",
    "\n",
    "Note how this context vector, $z$, does not have a $t$ subscript, meaning we re-use the same context vector returned by the encoder for every time-step in the decoder. \n",
    "\n",
    "Before, we predicted the next token, $\\hat{y}_{t+1}$, with the linear layer, $f$, only using the top-layer decoder hidden state at that time-step, $s_t$, as $\\hat{y}_{t+1}=f(s_t^L)$. Now, we also pass the embedding of current token, $d(y_t)$ and the context vector, $z$ to the linear layer.\n",
    "\n",
    "$$\\hat{y}_{t+1} = f(d(y_t), s_t, z)$$\n",
    "\n",
    "Thus, our decoder now looks something like this:\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq6.png?raw=1)\n",
    "\n",
    "Note, the initial hidden state, $s_0$, is still the context vector, $z$, so when generating the first token we are actually inputting two identical context vectors into the GRU.\n",
    "\n",
    "How do these two changes reduce the information compression? Well, hypothetically the decoder hidden states, $s_t$, no longer need to contain information about the source sequence as it is always available as an input. Thus, it only needs to contain information about what tokens it has generated so far. The addition of $y_t$ to the linear layer also means this layer can directly see what the token is, without having to get this information from the hidden state. \n",
    "\n",
    "However, this hypothesis is just a hypothesis, it is impossible to determine how the model actually uses the information provided to it (don't listen to anyone that says differently). Nevertheless, it is a solid intuition and the results seem to indicate that this modifications are a good idea!\n",
    "\n",
    "Within the implementation, we will pass $d(y_t)$ and $z$ to the GRU by concatenating them together, so the input dimensions to the GRU are now `emb_dim + hid_dim` (as context vector will be of size `hid_dim`). The linear layer will take $d(y_t), s_t$ and $z$ also by concatenating them together, hence the input dimensions are now `emb_dim + hid_dim*2`. We also don't pass a value of dropout to the GRU as it only uses a single layer.\n",
    "\n",
    "`forward` now takes a `context` argument. Inside of `forward`, we concatenate $y_t$ and $z$ as `emb_con` before feeding to the GRU, and we concatenate $d(y_t)$, $s_t$ and $z$ together as `output` before feeding it through the linear layer to receive our predictions, $\\hat{y}_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:55.541191Z",
     "start_time": "2021-01-26T16:45:55.536666Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "        Decoder takes an input and runs it through the lstm\n",
    "        decoder runs one word of batch\n",
    "        for example let's say the input size is [128]\n",
    "        here 128 means a batch of 128 words lets say all the 0th index 128 words\n",
    "        \n",
    "        first pass it through embedding dim of let's say 512\n",
    "        so the embedding output will be [1,batch_size,emb_dim][1,128,512]\n",
    "        then pass this ti lstm which will give you output and hidden cell state \n",
    "        outputs will have output at each time step so the first dim is src_len\n",
    "        but since decoder has only one word of batch the first dim is 0 here\n",
    "        hidden and cell os the dinal state output so they don't have src_len in the output as usual\n",
    "        let's say hidden dim for lstm is 10\n",
    "        outputs = [src_len,btach_size,hid_dim*n_directions][1,128,10] 1 here because decoder runs one word\n",
    "        hidden = [n layers * n directions, batch size, hid dim] [2,128,10] 2 for 2 layer, we are using 1 here\n",
    "        cell = [n layers * n directions, batch size, hid dim] [2,128,10] 2 for 2 layer, we are using 1 here\n",
    "    '''\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
    "\n",
    "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2,\n",
    "                                output_dim)  # we are using same dim here\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        \n",
    "        # input = [batch_size]\n",
    "        # hidden = [n_layers*n_direction,batch_size,hid_dim]\n",
    "        # context = [n_layers*n_direction,batch_size,hid_dim]\n",
    "        # n layers and n directions in the decoder will both always be 1,therefore ?? why always, only in this case, for example if we use 2 layers it may change\n",
    "        # hidden = [1, batch_size, hid_dim]\n",
    "        # context = [1, batch_size, hid_dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch_size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1,batch_size,emb_dim]\n",
    "        \n",
    "        emb_con = torch.cat((embedded, context),\n",
    "                             dim=2)  # last dim is output dim\n",
    "        # emb_con = [1,batch_size,emb_dim+hid_dim]\n",
    "\n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        # output = [seq_len,batch_size,hid_dim*n_directions]\n",
    "        # hidden = [n_layers * n_directions,batch_size,hid_dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim = 1)\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        # print('--------- check the shapes inside Decoder forward ---------')\n",
    "        # print('input shape {}, hidden shape {}, context shape {}'.format(input.shape,hidden.shape,context.shape))\n",
    "        # print('embedded shape {},emb_con shape {},output shape {},hidden shape {},'.format(embedded.shape,emb_con.shape,output.shape,hidden.shape))\n",
    "        # print('prediction shape {}'.format(prediction.shape))\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model\n",
    "\n",
    "Putting the encoder and decoder together, we get:\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq7.png?raw=1)\n",
    "\n",
    "Again, in this implementation we need to ensure the hidden dimensions in both the encoder and the decoder are the same.\n",
    "\n",
    "Briefly going over all of the steps:\n",
    "- the `outputs` tensor is created to hold all predictions, $\\hat{Y}$\n",
    "- the source sequence, $X$, is fed into the encoder to receive a `context` vector\n",
    "- the initial decoder hidden state is set to be the `context` vector, $s_0 = z = h_T$\n",
    "- we use a batch of `<sos>` tokens as the first `input`, $y_1$\n",
    "- we then decode within a loop:\n",
    "  - inserting the input token $y_t$, previous hidden state, $s_{t-1}$, and the context vector, $z$, into the decoder\n",
    "  - receiving a prediction, $\\hat{y}_{t+1}$, and a new hidden state, $s_t$\n",
    "  - we then decide if we are going to teacher force or not, setting the next input as appropriate (either the ground truth next token in the target sequence or the highest predicted next token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:45:58.806078Z",
     "start_time": "2021-01-26T16:45:58.802007Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        # src = [src_len,batch_size]\n",
    "        # trg = [trg_len,batch_size]\n",
    "\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "\n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "\n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "\n",
    "        # first inout to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "\n",
    "        # print('--------- check the shapes inside Seq2Seq forward ---------')\n",
    "        # print('src shape {}, trg shape {}'.format(src.shape,trg.shape))\n",
    "        # print('batch_size is {} , trg_len is {} , trg_vocab_size {} , outputs shape {} ,'.format(batch_size,trg_len,trg_vocab_size,outputs.shape))\n",
    "        # print('context vector {}, '.format(context.shape))\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            # insert input token embeddingm previous hidden state and the context state\n",
    "            # recieve output tensor i.e predictions and the new hidden state\n",
    "            # context/hidden dim is [1,batch_size,hid_dim_enc], 1 for 1 layer\n",
    "            # output dim [batch_size,vocab_len]\n",
    "            \n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # get the highest prediction token from out predictions\n",
    "            # top1 has the dim [batch_size,vocab_len]\n",
    "            # each example/word output a vector of target vocab length and we are taking the index of that\n",
    "            # out has trg_vocab size , let's say there are 1000 words and by taking index\n",
    "            # we are saying select the word which has highest value\n",
    "            top1 = output.argmax(\n",
    "                1)\n",
    "\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Seq2Seq Model\n",
    "\n",
    "We initialise our parameters, encoder, decoder and seq2seq model (placing it on the GPU if we have one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:46:01.974533Z",
     "start_time": "2021-01-26T16:46:01.972057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25004"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Question.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(Question.vocab)\n",
    "OUTPUT_DIM = len(Answer.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_PAD_IDX = Question.vocab.stoi[Question.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = ANSWER_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src, src_length = batch.questions\n",
    "        trg, trg_length = batch.answers\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if(i % 1000 == 0):\n",
    "            print(f\"{i} steps are done\")\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the evaluation loop, remembering to set the model to `eval` mode and turn off teaching forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_length = batch.questions\n",
    "            trg, trg_length = batch.answers\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define a timing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train our model, saving the parameters that give us the best \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'squad-attention.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the model on the test set using these \"best\" parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('squad-attention.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
